# Donald Trump Rally Speeches â€” NLP Portfolio Project

[![CI/CD Pipeline](https://github.com/JustaKris/Donald-Trump-Rally-Speeches-NLP/actions/workflows/ci.yml/badge.svg)](https://github.com/JustaKris/Donald-Trump-Rally-Speeches-NLP/actions/workflows/ci.yml)
[![Python 3.11+](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A professional data science portfolio project demonstrating advanced Natural Language Processing (NLP) techniques through comprehensive analysis of Donald Trump's 2019-2020 rally speeches. This project showcases production-ready code, interactive visualizations, REST API deployment, and actionable insights that would be valuable to employers seeking NLP and data analysis expertise.

## ğŸ¯ Project Highlights

- **35 rally speeches** (2019-2020) totaling 300,000+ words analyzed
- **Interactive Plotly dashboards** for exploratory data analysis
- **Production FastAPI application** with sentiment analysis endpoints
- **Deep learning sentiment analysis** using FinBERT (BERT-based transformer model)
- **Temporal trend analysis** revealing sentiment patterns over time
- **Docker containerization** for easy deployment to any cloud platform
- **Clean, documented, reusable code** following best practices
- **Reproducible environment** managed with Poetry

## ğŸš€ Live Demo

ğŸ”— **[Try the API](http://localhost:8000)** (Coming soon: deployed version)

ğŸ“š **[API Documentation](http://localhost:8000/docs)** - Interactive Swagger UI

ğŸ“– **[ReDoc Documentation](http://localhost:8000/redoc)** - Alternative API docs

## ğŸ“Š What's Inside

### `src/` â€” Production API Code

The project includes a production-ready FastAPI application for real-time NLP analysis:

- **`api.py`** â€” FastAPI application with RESTful endpoints
- **`models.py`** â€” Sentiment analysis model loading and inference
- **`preprocessing.py`** â€” Text cleaning, tokenization, and n-gram extraction
- **`utils.py`** â€” Data loading and statistical utilities

**API Endpoints:**
- `POST /analyze/sentiment` â€” Analyze sentiment of input text (FinBERT)
- `POST /analyze/words` â€” Word frequency analysis
- `POST /analyze/topics` â€” Topic/theme extraction
- `POST /analyze/ngrams` â€” N-gram extraction (bigrams, trigrams, etc.)
- `GET /speeches/stats` â€” Dataset statistics
- `GET /speeches/list` â€” List all speeches with metadata

### `static/` â€” Interactive Web Frontend

A beautiful, responsive web interface for interacting with the API without coding.

### `data/Donald Trump Rally Speeches/`

Plain text transcripts of 35 rally speeches from July 2019 to September 2020, providing rich corpus for NLP analysis.

### `notebooks/` â€” Three Production-Ready Jupyter Notebooks

#### 1. **Word Clouds.ipynb** â€” Exploratory Text Analysis

- Interactive word frequency visualizations with Plotly
- N-gram analysis (unigrams, bigrams, trigrams)
- Temporal word usage patterns comparing 2019 vs 2020
- Topic identification and frequency tracking
- Comprehensive statistical summaries

**Key Technologies:** pandas, NLTK, WordCloud, Plotly, tqdm

#### 2. **Sentiment Analysis.ipynb** â€” Deep Learning NLP

- FinBERT-based sentiment classification (positive/negative/neutral)
- Chunked processing for long documents
- Speech-by-speech sentiment scoring with chunk-level granularity
- Interactive dashboards: heatmaps, timelines, distributions
- Year-over-year statistical comparison
- Moving average trend analysis
- Results exported for downstream use

**Key Technologies:** TensorFlow, Transformers (Hugging Face), FinBERT, Plotly

#### 3. **Masked Language Modeling.ipynb** â€” Advanced Transformer Fine-tuning

- Custom DistilBERT fine-tuning on domain-specific corpus
- Whole-word masking implementation
- Model evaluation with perplexity metrics
- Comparative analysis: base model vs fine-tuned model
- Demonstrates understanding of transfer learning and model training

**Key Technologies:** TensorFlow, Transformers, Datasets (Hugging Face), DistilBERT

## ğŸš€ Key Skills Demonstrated

### Data Science & Analysis

- **Data wrangling**: Loading, parsing, and structuring unstructured text data
- **Exploratory Data Analysis**: Statistical summaries, distributions, temporal patterns
- **Feature engineering**: N-gram extraction, stopword filtering, custom metrics

### NLP & Machine Learning

- **Text preprocessing**: Tokenization, chunking, stopword removal
- **Sentiment analysis**: Deep learning classification with pre-trained transformers
- **Language modeling**: Fine-tuning BERT-based models on domain-specific data
- **Model evaluation**: Perplexity, accuracy metrics, comparative analysis

### Visualization & Communication

- **Interactive dashboards**: Plotly-based multi-panel visualizations
- **Time series analysis**: Trend lines, moving averages, year-over-year comparisons
- **Clear documentation**: Markdown cells, docstrings, and inline comments
- **Storytelling with data**: Extracting actionable insights from raw text

### Software Engineering

- **Production-ready code**: Modular functions, type hints, error handling
- **Environment management**: Poetry for dependency management
- **Best practices**: Progress bars, logging, reproducible workflows
- **Clean code principles**: DRY, separation of concerns, readability

## ğŸ“ˆ Sample Insights from the Analysis

- **Sentiment patterns**: Identified temporal shifts in speech sentiment between 2019 and 2020
- **Vocabulary evolution**: Tracked how language usage changed over the campaign period
- **Topic prevalence**: Quantified mentions of key themes (economy, immigration, media)
- **Speech characteristics**: Average speech length of 8,500+ words with consistent patterns

## ğŸš€ Quick Start

### Option 1: Run the API (Recommended for Demo)

1. **Install dependencies**

   ```powershell
   poetry install
   ```

2. **Start the FastAPI server**

   ```powershell
   poetry run uvicorn src.api:app --reload
   ```

3. **Access the application**
   - **Web Interface:** <http://localhost:8000>
   - **API Docs:** <http://localhost:8000/docs>
   - **ReDoc:** <http://localhost:8000/redoc>

### Option 2: Run with Docker

1. **Build the Docker image**

   ```powershell
   docker build -t trump-speeches-nlp-api .
   ```

2. **Run the container**

   ```powershell
   docker run -d -p 8000:8000 trump-speeches-nlp-api
   ```

3. **Or use Docker Compose**

   ```powershell
   docker-compose up -d
   ```

### Option 3: Explore Jupyter Notebooks

1. **Install dependencies**

   ```powershell
   poetry install
   ```

2. **Activate the environment**

   ```powershell
   poetry shell
   ```

3. **Launch Jupyter Lab**

   ```powershell
   poetry run jupyter lab
   ```

4. **Run notebooks in order**
   - Start with `1. Word Frequency & Topics Analysis.ipynb`
   - Then `2. Sentiment Analysis.ipynb`
   - Finally `3. Masked Language Modeling.ipynb` (optional)

### First-Time Setup

Some notebooks require NLTK data. Run once in a notebook cell:

```python
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
```

## ğŸ§ª Testing & Code Quality

This project includes comprehensive testing and code quality tools to demonstrate professional software engineering practices.

### Run Tests

```powershell
# Install dev dependencies
poetry install --with dev

# Run all tests with coverage
poetry run pytest

# Run only unit tests
poetry run pytest -m unit

# Run only integration tests
poetry run pytest -m integration

# Generate HTML coverage report
poetry run pytest --cov=src --cov-report=html
```

### Code Quality Checks

```powershell
# Format code
poetry run black src/

# Lint code
poetry run flake8 src/

# Sort imports
poetry run isort src/

# Type checking
poetry run mypy src/

# Run all checks
poetry run black src/ && poetry run isort src/ && poetry run flake8 src/ && poetry run pytest
```

### CI/CD Pipeline

The project uses GitHub Actions for continuous integration:
- âœ… **Automated testing** on Python 3.11, 3.12, 3.13
- âœ… **Code quality checks** (black, flake8, isort, mypy)
- âœ… **Security scanning** (safety, bandit)
- âœ… **Docker image build** and health checks

See [`.github/workflows/ci.yml`](.github/workflows/ci.yml) for the full pipeline configuration.

For detailed testing documentation, see [`docs/TESTING.md`](docs/TESTING.md).

## ğŸ“¦ Dependencies
```

## ğŸ“¦ Core Dependencies

**API & Web Framework:**

```toml
fastapi = "^0.115.0"          # Modern async API framework
uvicorn[standard] = "^0.32.0" # ASGI server with auto-reload
python-multipart = "^0.0.12"  # Form data parsing
```

**NLP & Machine Learning:**

```toml
transformers = "^4.57.1"      # HuggingFace transformers (BERT, DistilBERT)
tensorflow = "^2.20.0"        # Deep learning framework
torch = "^2.9.0"              # PyTorch (transformers backend)
nltk = "^3.9.2"               # Natural Language Toolkit
scikit-learn = "^1.7.2"       # ML utilities
```

**Data & Visualization:**

```toml
pandas = "^2.3.3"             # Data manipulation
numpy = "^2.3.4"              # Numerical computing
plotly = "^6.3.1"             # Interactive visualizations
matplotlib = "^3.10.7"        # Static plots
seaborn = "^0.13.2"           # Statistical visualizations
wordcloud = "^1.9.4"          # Word cloud generation
```

**Development:**

```toml
jupyterlab = "^4.4.10"        # Interactive notebooks
ipykernel = "^7.0.1"          # Jupyter kernel
tqdm = "^4.67.1"              # Progress bars
```

**Note**: TensorFlow installs CPU-only by default. For GPU support, follow [PyTorch's official guide](https://pytorch.org/get-started/locally/) to install the appropriate CUDA-enabled version.

## ğŸ’¡ Project Structure

```
Donald-Trump-Rally-Speeches-NLP/
â”‚
â”œâ”€â”€ src/                                # Production API code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                         # FastAPI application
â”‚   â”œâ”€â”€ models.py                      # ML model loading & inference
â”‚   â”œâ”€â”€ preprocessing.py               # Text preprocessing utilities
â”‚   â””â”€â”€ utils.py                       # Data loading & statistics
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html                     # Interactive web frontend
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Donald Trump Rally Speeches/   # 35 .txt files (one per speech)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1. Word Frequency & Topics Analysis.ipynb
â”‚   â”œâ”€â”€ 2. Sentiment Analysis.ipynb
â”‚   â””â”€â”€ 3. Masked Language Modeling.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ COMMANDS.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md                  # Deployment guide
â”‚   â””â”€â”€ TESTING.md                     # Testing & code quality guide
â”‚
â”œâ”€â”€ tests/                             # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_preprocessing.py          # Unit tests for preprocessing
â”‚   â”œâ”€â”€ test_utils.py                  # Unit tests for utilities
â”‚   â””â”€â”€ test_api.py                    # Integration tests for API
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                     # GitHub Actions CI/CD pipeline
â”‚
â”œâ”€â”€ .azure/
â”‚   â””â”€â”€ deployment-guide.txt           # Azure deployment instructions
â”‚
â”œâ”€â”€ pytest.ini                         # Pytest configuration
â”œâ”€â”€ .flake8                            # Flake8 linting rules
â”œâ”€â”€ Dockerfile                         # Docker container definition
â”œâ”€â”€ docker-compose.yml                 # Docker Compose configuration
â”œâ”€â”€ render.yaml                        # Render deployment config
â”œâ”€â”€ pyproject.toml                     # Poetry dependencies + tool configs
â”œâ”€â”€ poetry.lock                        # Locked dependency versions
â””â”€â”€ README.md                          # This file
```

## ğŸ“ Learning Outcomes & Portfolio Value

This project demonstrates capabilities that are directly applicable to industry roles:

### For Data Science Roles

- End-to-end analysis from raw text to insights
- Statistical rigor and proper evaluation methods
- Clear communication of findings
- Production deployment experience

### For ML Engineering Roles

- Working with state-of-the-art transformer models
- Efficient data processing pipelines
- Model fine-tuning and deployment considerations
- RESTful API design and implementation
- Docker containerization and cloud deployment

### For Analytics Roles

- Interactive visualization best practices
- Temporal trend analysis
- Stakeholder-ready reporting
- Web-based dashboards

### Full-Stack ML Skills

- **Backend:** FastAPI, Python, async programming
- **ML/NLP:** BERT models, sentiment analysis, text preprocessing
- **DevOps:** Docker, container orchestration, cloud deployment, CI/CD pipelines
- **Frontend:** HTML/CSS/JavaScript, responsive design
- **Data Engineering:** ETL pipelines, data validation
- **Testing:** pytest, unit/integration testing, code coverage
- **Code Quality:** Linting (flake8), formatting (black), type checking (mypy)

## ğŸš¢ Deployment

This project is ready to deploy to multiple cloud platforms!

### Deployment Options

- **[Render](https://render.com)** â€” Free tier available, automatic deployments from Git
- **[Azure App Service](https://azure.microsoft.com/en-us/services/app-service/)** â€” Enterprise-grade, excellent for portfolio
- **[Railway](https://railway.app)** â€” Simple deployment with free credits
- **[Fly.io](https://fly.io)** â€” Global edge deployment

### Quick Deploy to Render

1. Push your code to GitHub
2. Connect repository to Render
3. Deploy with one click using `render.yaml`

### Deploy with Docker

```powershell
# Build image
docker build -t trump-speeches-nlp-api .

# Run locally
docker run -p 8000:8000 trump-speeches-nlp-api

# Deploy to any cloud platform that supports Docker
```

ğŸ“– **Full deployment instructions:** See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)

## ğŸ”§ Troubleshooting

### Common Issues

#### SSL Certificate Errors (Hugging Face downloads)

```python
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
```

#### Out of Memory (TensorFlow/Sentiment Analysis)

- Reduce batch size in sentiment analysis
- Use smaller models (e.g., `distilbert-base-uncased`)
- Close other memory-intensive applications

#### Slow Performance

- MLM training: Use GPU if available, or reduce epochs
- Sentiment analysis: Already optimized with chunking and progress bars

## ğŸ“ Next Steps & Enhancements

**Current features:**

- âœ… FastAPI REST API with sentiment analysis
- âœ… Interactive web frontend
- âœ… Docker containerization
- âœ… Deployment configurations for Render and Azure
- âœ… Comprehensive documentation

**Potential additions to strengthen the portfolio:**

1. **Cloud deployment:** Deploy to Render or Azure and add live demo link
2. **CI/CD pipeline:** GitHub Actions for automated testing and deployment
3. **Testing suite:** Pytest for API endpoints and data processing
4. **Enhanced frontend:** Add charts and visualizations using Plotly.js
5. **Authentication:** Add API keys or OAuth for production use
6. **Caching:** Redis for model predictions and frequently accessed data
7. **Rate limiting:** Protect API from abuse
8. **Monitoring:** Application performance monitoring (APM)
9. **Database integration:** PostgreSQL for storing analysis results

## ğŸ“„ License & Attribution

This repository is for educational and portfolio purposes. The speech transcripts are publicly available data used for demonstrative NLP analysis.

**Technologies Used:**

- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [FinBERT](https://huggingface.co/ProsusAI/finbert) for sentiment analysis
- [Plotly](https://plotly.com/python/) for interactive visualizations
- [Poetry](https://python-poetry.org/) for dependency management

---

## ğŸ“« Contact

**Kristiyan Bonev** | [GitHub](https://github.com/JustaKris)

*This project showcases practical NLP skills and modern data science workflows. Feel free to explore the notebooks and reach out with questions!*
