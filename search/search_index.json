{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Trump Speeches NLP Chatbot \u2014 Documentation","text":"<p>Welcome to the documentation for the Trump Speeches NLP Chatbot project, a production-ready FastAPI application demonstrating modern AI engineering practices with RAG (Retrieval-Augmented Generation), semantic search, and sentiment analysis.</p>"},{"location":"#what-this-project-demonstrates","title":"\ud83c\udfaf What This Project Demonstrates","text":"<p>This portfolio project showcases:</p> <ul> <li>RAG System Architecture \u2014 ChromaDB vector database + MPNet embeddings + Google Gemini LLM</li> <li>Hybrid Search \u2014 Combining semantic search with BM25 keyword matching and cross-encoder reranking</li> <li>Production FastAPI Development \u2014 RESTful API design with 12+ endpoints</li> <li>Entity Analytics \u2014 Automatic entity extraction with sentiment analysis</li> <li>DevOps Practices \u2014 Docker, CI/CD, comprehensive testing, code quality tools</li> </ul>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":""},{"location":"#getting-started","title":"Getting Started","text":"<p>New to the project? Start here:</p> <ul> <li>Quickstart Guide \u2014 Get the API running in 5 minutes</li> <li>Deployment Guide \u2014 Deploy to Render, Azure, or Docker</li> </ul>"},{"location":"#how-to-guides","title":"How-To Guides","text":"<p>Task-oriented guides for specific features:</p> <ul> <li>Testing Guide \u2014 Run tests, code quality checks, and CI/CD</li> <li>Entity Analytics \u2014 Analyze entities mentioned in speeches</li> </ul>"},{"location":"#reference-documentation","title":"Reference Documentation","text":"<p>Deep technical documentation:</p> <ul> <li>System Architecture \u2014 System design, components, and diagrams</li> <li>RAG Features \u2014 Detailed RAG implementation documentation</li> </ul>"},{"location":"#quick-links","title":"\ud83d\ude80 Quick Links","text":"<ul> <li>GitHub Repository \u2014 Source code and issues</li> <li>API Documentation (Swagger) \u2014 Interactive API docs (when running locally)</li> <li>API Documentation (ReDoc) \u2014 Alternative API docs</li> </ul>"},{"location":"#core-features","title":"\ud83e\udd16 Core Features","text":""},{"location":"#rag-qa-system","title":"RAG Q&amp;A System","text":"<p>Ask natural language questions about 35 political speeches (300,000+ words):</p> <pre><code>curl -X POST http://localhost:8000/rag/ask \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"question\": \"What economic policies were discussed?\", \"top_k\": 5}'\n</code></pre> <p>Features: - Semantic search using MPNet embeddings (768-dimensional) - Hybrid search combining vector similarity and BM25 keyword matching - Cross-encoder reranking for improved precision - Multi-factor confidence scoring - Entity extraction and analytics - Google Gemini LLM for answer generation</p>"},{"location":"#nlp-endpoints","title":"NLP Endpoints","text":"<p>Traditional NLP analysis: - Sentiment Analysis \u2014 FinBERT transformer model - Topic Extraction \u2014 TF-IDF based topic modeling - Word Frequency \u2014 Statistical text analysis - N-gram Analysis \u2014 Bigram and trigram extraction</p>"},{"location":"#interactive-web-interface","title":"Interactive Web Interface","text":"<p>Single-page application at the root (<code>/</code>) for testing all features without writing code.</p>"},{"location":"#technology-stack","title":"\ud83d\udee0\ufe0f Technology Stack","text":"<p>AI/ML: - ChromaDB (vector database) - sentence-transformers (MPNet) - Google Gemini (LLM) - Hugging Face Transformers (FinBERT)</p> <p>Backend: - FastAPI (REST API) - Pydantic (validation) - NLTK (preprocessing)</p> <p>DevOps: - Docker + Docker Compose - GitHub Actions (CI/CD) - pytest (testing) - Black, flake8, mypy (code quality)</p>"},{"location":"#example-use-cases","title":"\ud83d\udca1 Example Use Cases","text":"<ol> <li>Political Speech Analysis \u2014 Extract themes, sentiment, and talking points</li> <li>RAG System Demo \u2014 Show how to build Q&amp;A over large text corpora</li> <li>Entity Analytics \u2014 Track mentions of people, places, and topics</li> <li>Hybrid Search \u2014 Demonstrate combining semantic and keyword search</li> </ol>"},{"location":"#learning-resources","title":"\ud83c\udf93 Learning Resources","text":"<ul> <li>Architecture diagrams in the Architecture doc</li> <li>RAG implementation details in RAG Features</li> <li>Testing strategy in Testing Guide</li> <li>Deployment options in Deployment Guide</li> </ul>"},{"location":"#support-contributing","title":"\ud83d\udcde Support &amp; Contributing","text":"<ul> <li>Issues: GitHub Issues</li> <li>Author: Kristiyan Bonev</li> <li>License: MIT</li> </ul> <p>Ready to get started? Head to the Quickstart Guide \u2192</p>"},{"location":"guides/deployment/","title":"Deployment Guide","text":"<p>This guide covers deploying the Trump Speeches NLP Chatbot API to various platforms.</p>"},{"location":"guides/deployment/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Local Development</li> <li>Docker Deployment</li> <li>Render Deployment</li> <li>Azure App Service Deployment</li> <li>CI/CD with GitHub Actions</li> <li>Environment Variables</li> </ul>"},{"location":"guides/deployment/#local-development","title":"Local Development","text":""},{"location":"guides/deployment/#running-without-docker","title":"Running Without Docker","text":"<ol> <li>Create a virtual environment (optional but recommended):</li> </ol> <pre><code># Create venv with default Python version\nuv venv\n\n# Create venv with specific Python version\nuv venv --python 3.12\nuv venv --python 3.11\n\n# Create venv in custom directory\nuv venv .venv-dev\n\n# Activate the virtual environment (Windows PowerShell)\n.venv\\Scripts\\Activate.ps1\n\n# Deactivate when done\ndeactivate\n</code></pre> <ol> <li>Install dependencies:</li> </ol> <pre><code># Install all production dependencies\nuv sync\n\n# Install with specific dependency groups\nuv sync --group dev              # Include dev tools\nuv sync --group docs             # Include docs tools\nuv sync --group notebooks        # Include notebook tools\nuv sync --all-groups             # Include all optional groups\n\n# Install without optional groups\nuv sync --no-group dev --no-group docs --no-group notebooks\n\n# Upgrade all dependencies to latest compatible versions\nuv sync --upgrade\n\n# Install from scratch (ignore lock file)\nuv sync --reinstall\n</code></pre> <ol> <li>Add or remove packages:</li> </ol> <pre><code># Add a new package\nuv add requests\nuv add \"fastapi&gt;=0.100.0\"\n\n# Add to a specific group\nuv add --group dev pytest\nuv add --group docs mkdocs-material\n\n# Remove a package\nuv remove requests\n\n# Update lock file without installing\nuv lock\n\n# Update specific package\nuv lock --upgrade-package fastapi\n</code></pre> <ol> <li>Run commands:</li> </ol> <pre><code># Run the API server\nuv run uvicorn src.api:app --reload\n\n# Run with custom host and port\nuv run uvicorn src.api:app --host 0.0.0.0 --port 8001 --reload\n\n# Run tests\nuv run pytest\nuv run pytest -v --cov=src\n\n# Run code formatters\nuv run black src/\nuv run isort src/\n\n# Run linters\nuv run flake8 src/\nuv run mypy src/\n\n# Run Python scripts\nuv run python scripts/migrate_rag_embeddings.py\n\n# Run Python REPL with dependencies\nuv run python\n</code></pre> <ol> <li>Manage Python versions:</li> </ol> <pre><code># List available Python versions\nuv python list\n\n# Install a specific Python version\nuv python install 3.12\nuv python install 3.11.8\n\n# Pin Python version for project\nuv python pin 3.12\n\n# Show current Python version\nuv python find\n</code></pre> <ol> <li>Export dependencies:</li> </ol> <pre><code># Export to requirements.txt\nuv pip compile pyproject.toml -o requirements.txt\n\n# Export with specific groups excluded\nuv export --no-group dev --no-group docs -o requirements.txt\n\n# Export in different formats\nuv export --format requirements-txt\n</code></pre> <ol> <li>Access the application:</li> <li>Frontend: http://localhost:8000</li> <li>API Docs: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ol>"},{"location":"guides/deployment/#docker-deployment","title":"Docker Deployment","text":""},{"location":"guides/deployment/#build-and-run-with-docker","title":"Build and Run with Docker","text":"<ol> <li>Build the Docker image:</li> </ol> <p>```powershell    docker build -t trump-speeches-nlp-chatbot .</p> <p># Build with no cache (clean build)    ```powershell docker build --no-cache -t trump-speeches-nlp-chatbot . <pre><code>   # Build with a specific tag\n   docker build -t trump-speeches-nlp-chatbot:v1.0.0 .\n   ```\n\n2. **Run the container:**\n\n   ```powershell\n   # Basic run\n   docker run --rm -it -p 8000:8000 --env-file .env --name nlp-chatbot trump-speeches-nlp-chatbot\n\n   # Run in detached mode (background)\n   docker run -d -p 8000:8000 --env-file .env --name nlp-chatbot trump-speeches-nlp-chatbot\n\n   # Run with persistent ChromaDB volume\n   docker run --rm -it -p 8000:8000 -v \"${PWD}/data/chromadb:/app/data/chromadb\" --env-file .env --name nlp-chatbot trump-speeches-nlp-chatbot\n   ```\n\n3. **View logs:**\n\n   ```powershell\n   # Follow logs (real-time)\n   docker logs -f nlp-chatbot\n\n   # View last 100 lines\n   docker logs --tail 100 nlp-chatbot\n\n   # View logs with timestamps\n   docker logs -t nlp-chatbot\n   ```\n\n4. **Manage containers:**\n\n   ```powershell\n   # Stop the container\n   docker stop nlp-chatbot\n\n   # Start a stopped container\n   docker start nlp-chatbot\n\n   # Restart the container\n   docker restart nlp-chatbot\n\n   # Remove the container\n   docker rm nlp-chatbot\n\n   # Remove with force (even if running)\n   docker rm -f nlp-chatbot\n   ```\n\n5. **Tag and push to Docker Hub:**\n\n   ```powershell\n   # Tag for Docker Hub\n   docker tag trump-speeches-nlp-chatbot yourusername/trump-speeches-nlp-chatbot:latest\n   docker tag trump-speeches-nlp-chatbot yourusername/trump-speeches-nlp-chatbot:v1.0.0\n\n   # Login to Docker Hub\n   docker login\n\n   # Push to Docker Hub\n   docker push yourusername/trump-speeches-nlp-chatbot:latest\n   docker push yourusername/trump-speeches-nlp-chatbot:v1.0.0\n\n   # Push all tags\n   docker push --all-tags yourusername/trump-speeches-nlp-chatbot\n   ```\n\n6. **Clean up Docker resources:**\n\n   ```powershell\n   # Remove unused images\n   docker image prune\n\n   # Remove all stopped containers\n   docker container prune\n\n   # Remove all unused containers, networks, images\n   docker system prune\n\n   # Remove everything (including volumes)\n   docker system prune -a --volumes\n   ```\n\n### Using Docker Compose\n\n**Production mode:**\n\n```powershell\ndocker-compose up -d\n</code></pre></p> <p>Development mode (with hot reload):</p> <pre><code>+\n</code></pre> <p>Stop services:</p> <pre><code>docker-compose down\n</code></pre>"},{"location":"guides/deployment/#render-deployment","title":"Render Deployment","text":"<p>Render offers free hosting with automatic deployments using Docker images.</p>"},{"location":"guides/deployment/#deployment-strategy","title":"Deployment Strategy","text":"<p>This project uses a Docker-based deployment approach for Render:</p> <ol> <li>GitHub Actions builds and pushes Docker images to Docker Hub</li> <li>Render pulls and deploys the pre-built images</li> <li>Benefits: Faster deployments, consistent environments, easier rollbacks</li> </ol>"},{"location":"guides/deployment/#prerequisites","title":"Prerequisites","text":"<ol> <li>Docker Hub Account (free)</li> <li>Sign up at https://hub.docker.com</li> <li> <p>Create a repository named <code>trump-speeches-nlp-chatbot</code></p> </li> <li> <p>Render Account (free)</p> </li> <li> <p>Sign up at https://render.com</p> </li> <li> <p>GitHub Repository connected to your account</p> </li> </ol>"},{"location":"guides/deployment/#step-1-configure-github-secrets","title":"Step 1: Configure GitHub Secrets","text":"<p>Add these secrets to your GitHub repository (Settings \u2192 Secrets and variables \u2192 Actions):</p> <ol> <li><code>DOCKERHUB_USERNAME</code> - Your Docker Hub username</li> <li><code>DOCKERHUB_TOKEN</code> - Docker Hub access token</li> <li>Go to Docker Hub \u2192 Account Settings \u2192 Security \u2192 New Access Token</li> <li>Copy the token and save it as a GitHub secret</li> </ol>"},{"location":"guides/deployment/#step-2-update-renderyaml","title":"Step 2: Update render.yaml","text":"<p>Edit <code>render.yaml</code> and replace <code>&lt;your-dockerhub-username&gt;</code> with your actual Docker Hub username:</p> <pre><code>image:\n  url: docker.io/your-username/trump-speeches-nlp-chatbot:latest\n</code></pre>"},{"location":"guides/deployment/#step-3-deploy-to-render","title":"Step 3: Deploy to Render","text":"<p>Option A: Using Blueprint (Recommended)</p> <ol> <li>Go to Render Dashboard \u2192 \"Blueprints\"</li> <li>Click \"New Blueprint Instance\"</li> <li>Connect your GitHub repository</li> <li>Render will detect <code>.render/render.yaml</code> and configure everything automatically</li> <li>Click \"Apply\" to create the service</li> </ol> <p>Option B: Manual Configuration</p> <ol> <li>Go to Render Dashboard \u2192 \"New +\" \u2192 \"Web Service\"</li> <li>Choose \"Deploy an existing image from a registry\"</li> <li>Configure:</li> <li>Image URL: <code>docker.io/your-username/trump-speeches-nlp-chatbot:latest</code></li> <li>Name: <code>trump-speeches-nlp-chatbot</code></li> <li>Plan: Free</li> <li>Add environment variable:</li> <li><code>PORT</code> = <code>8000</code></li> <li>Set Health Check Path: <code>/health</code></li> <li>Click \"Create Web Service\"</li> </ol>"},{"location":"guides/deployment/#step-4-trigger-deployment","title":"Step 4: Trigger Deployment","text":"<p>Push to <code>main</code> branch or manually trigger the workflow:</p> <pre><code>git push origin main\n</code></pre> <p>This will: 1. Build the Docker image 2. Push it to Docker Hub 3. Render automatically detects the new image and deploys it</p>"},{"location":"guides/deployment/#accessing-your-render-app","title":"Accessing Your Render App","text":"<p>Your API will be available at: <code>https://trump-speeches-nlp-chatbot.onrender.com</code></p> <p>Note: Free tier apps spin down after 15 minutes of inactivity. First request may take 30-60 seconds to wake the service.</p>"},{"location":"guides/deployment/#monitoring-logs","title":"Monitoring &amp; Logs","text":"<ul> <li>Logs: Render Dashboard \u2192 Your Service \u2192 Logs tab</li> <li>Metrics: Render Dashboard \u2192 Your Service \u2192 Metrics tab</li> <li>Manual Deploy: Render Dashboard \u2192 Your Service \u2192 Manual Deploy button</li> </ul>"},{"location":"guides/deployment/#upgrading-from-free-tier","title":"Upgrading from Free Tier","text":"<p>For better performance: - Starter Plan: $7/month (512 MB RAM, 0.5 CPU) - No cold starts - Faster response times - Better for production use</p>"},{"location":"guides/deployment/#azure-app-service-deployment","title":"Azure App Service Deployment","text":""},{"location":"guides/deployment/#deployment-strategy_1","title":"Deployment Strategy","text":"<p>This project supports two Azure deployment approaches:</p> <ol> <li>Azure Container Registry (ACR) - Recommended for enterprise/production (default)</li> <li>Docker Hub - Alternative for simpler setups or cross-platform deployments</li> </ol> <p>Both use the same GitHub Actions workflow with conditional logic.</p>"},{"location":"guides/deployment/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Azure account (free tier available)</li> <li>Azure CLI installed: https://docs.microsoft.com/en-us/cli/azure/install-azure-cli</li> <li>Docker Hub account (if using Docker Hub approach)</li> </ul>"},{"location":"guides/deployment/#option-1-deploy-with-azure-container-registry-recommended","title":"Option 1: Deploy with Azure Container Registry (Recommended)","text":""},{"location":"guides/deployment/#step-1-create-azure-resources","title":"Step 1: Create Azure Resources","text":"<pre><code># Login to Azure\naz login\n\n# Create a resource group\naz group create --name trump-nlp-rg --location eastus\n\n# Create Azure Container Registry\naz acr create `\n  --resource-group trump-nlp-rg `\n  --name trumpnlpacr `\n  --sku Basic `\n  --admin-enabled true\n\n# Create an App Service plan (B1 or F1 tier)\naz appservice plan create `\n  --name trump-nlp-plan `\n  --resource-group trump-nlp-rg `\n  --sku B1 `\n  --is-linux\n\n# Create a web app for containers\naz webapp create `\n  --resource-group trump-nlp-rg `\n  --plan trump-nlp-plan `\n  --name trump-speeches-nlp-chatbot `\n  --deployment-container-image-name trumpnlpacr.azurecr.io/trump-speeches-nlp-chatbot:latest\n\n# Configure port\naz webapp config appsettings set `\n  --resource-group trump-nlp-rg `\n  --name trump-speeches-nlp-chatbot `\n  --settings WEBSITES_PORT=8000\n\n# Enable ACR integration\naz webapp config container set `\n  --resource-group trump-nlp-rg `\n  --name trump-speeches-nlp-chatbot `\n  --docker-custom-image-name trumpnlpacr.azurecr.io/trump-speeches-nlp-chatbot:latest `\n  --docker-registry-server-url https://trumpnlpacr.azurecr.io\n</code></pre>"},{"location":"guides/deployment/#step-2-configure-github-secrets-for-acr","title":"Step 2: Configure GitHub Secrets for ACR","text":"<p>Add these secrets to your GitHub repository:</p> <ol> <li><code>AZURE_CREDENTIALS</code> - Service principal credentials</li> </ol> <pre><code>az ad sp create-for-rbac --name \"github-actions-trump-nlp\" --sdk-auth --role contributor --scopes /subscriptions/{subscription-id}/resourceGroups/trump-nlp-rg\n</code></pre> <p>Copy the entire JSON output and save as secret.</p> <ol> <li> <p><code>AZURE_REGISTRY_LOGIN_SERVER</code> - e.g., <code>trumpnlpacr.azurecr.io</code></p> </li> <li> <p><code>AZURE_REGISTRY_USERNAME</code> and <code>AZURE_REGISTRY_PASSWORD</code></p> </li> </ol> <pre><code>az acr credential show --name trumpnlpacr\n</code></pre> <ol> <li><code>AZURE_WEBAPP_NAME</code> - e.g., <code>trump-speeches-nlp-chatbot</code></li> </ol>"},{"location":"guides/deployment/#step-3-deploy","title":"Step 3: Deploy","text":"<p>Push to <code>main</code> branch:</p> <pre><code>git push origin main\n</code></pre> <p>GitHub Actions will automatically: 1. Build Docker image 2. Push to Azure Container Registry 3. Deploy to Azure Web App 4. Run health checks</p>"},{"location":"guides/deployment/#option-2-deploy-with-docker-hub","title":"Option 2: Deploy with Docker Hub","text":"<p>This approach shares the same Docker images used for Render deployment.</p>"},{"location":"guides/deployment/#step-1-create-azure-resources_1","title":"Step 1: Create Azure Resources","text":"<pre><code># Login to Azure\naz login\n\n# Create a resource group\naz group create --name trump-nlp-rg --location eastus\n\n# Create an App Service plan\naz appservice plan create `\n  --name trump-nlp-plan `\n  --resource-group trump-nlp-rg `\n  --sku B1 `\n  --is-linux\n\n# Create a web app using Docker Hub image\naz webapp create `\n  --resource-group trump-nlp-rg `\n  --plan trump-nlp-plan `\n  --name trump-speeches-nlp-chatbot `\n  --deployment-container-image-name docker.io/your-username/trump-speeches-nlp-chatbot:latest\n\n# Configure port\naz webapp config appsettings set `\n  --resource-group trump-nlp-rg `\n  --name trump-speeches-nlp-chatbot `\n  --settings WEBSITES_PORT=8000\n</code></pre>"},{"location":"guides/deployment/#step-2-configure-github-secrets-for-docker-hub","title":"Step 2: Configure GitHub Secrets for Docker Hub","text":"<p>You'll need the same Docker Hub secrets as for Render:</p> <ol> <li><code>DOCKERHUB_USERNAME</code></li> <li><code>DOCKERHUB_TOKEN</code></li> <li><code>AZURE_CREDENTIALS</code> (same as Option 1)</li> <li><code>AZURE_WEBAPP_NAME</code></li> </ol>"},{"location":"guides/deployment/#step-3-deploy-with-docker-hub","title":"Step 3: Deploy with Docker Hub","text":"<p>Manually trigger the workflow:</p> <ol> <li>Go to GitHub \u2192 Actions \u2192 \"Deploy to Azure\"</li> <li>Click \"Run workflow\"</li> <li>Check \"Use Docker Hub instead of ACR\"</li> <li>Click \"Run workflow\"</li> </ol>"},{"location":"guides/deployment/#accessing-your-azure-app","title":"Accessing Your Azure App","text":"<p>Your API will be available at: <code>https://trump-speeches-nlp-chatbot.azurewebsites.net</code></p>"},{"location":"guides/deployment/#monitoring-and-logs","title":"Monitoring and Logs","text":"<pre><code># Stream logs\naz webapp log tail --resource-group trump-nlp-rg --name trump-speeches-nlp-chatbot\n\n# View metrics\naz monitor metrics list `\n  --resource /subscriptions/{subscription-id}/resourceGroups/trump-nlp-rg/providers/Microsoft.Web/sites/trump-speeches-nlp-chatbot `\n  --metric-names Requests,ResponseTime,Http5xx\n\n# Open in Azure Portal\naz webapp browse --resource-group trump-nlp-rg --name trump-speeches-nlp-chatbot\n</code></pre>"},{"location":"guides/deployment/#updating-the-deployment","title":"Updating the Deployment","text":"<p>Deployments are automatic on push to <code>main</code>. To manually update:</p> <pre><code># Trigger GitHub Actions workflow manually\n# Or restart the web app to pull latest image\naz webapp restart --resource-group trump-nlp-rg --name trump-speeches-nlp-chatbot\n</code></pre>"},{"location":"guides/deployment/#cicd-with-github-actions","title":"CI/CD with GitHub Actions","text":"<p>This project includes automated CI/CD pipelines using GitHub Actions. The workflows are split into multiple files for better organization:</p>"},{"location":"guides/deployment/#workflow-files","title":"Workflow Files","text":"<p>All workflows are located in <code>.github/workflows/</code>:</p> <ul> <li><code>ci.yml</code> - Tests &amp; Linting</li> <li>Runs on: All pushes and PRs to <code>main</code>, <code>develop</code>, <code>feature/*</code></li> <li>Jobs: Unit tests, integration tests, code quality checks (flake8, black, isort, mypy)</li> <li> <p>Python versions tested: 3.11, 3.12, 3.13</p> </li> <li> <p><code>security.yml</code> - Security Scans</p> </li> <li>Runs on: All pushes and PRs, plus weekly schedule (Mondays 9 AM UTC)</li> <li> <p>Jobs: Dependency vulnerability scanning (pip-audit), code security analysis (bandit)</p> </li> <li> <p><code>deploy-render.yml</code> - Render Deployment</p> </li> <li>Runs on: Push to <code>main</code> branch only</li> <li>Jobs: Build Docker image, push to Docker Hub, test container</li> <li> <p>Render auto-deploys when new images are detected</p> </li> <li> <p><code>deploy-azure.yml</code> - Azure Deployment</p> </li> <li>Runs on: Push to <code>main</code> branch (manual trigger also available)</li> <li>Jobs: Build &amp; push to ACR/Docker Hub, deploy to Azure Web App, health check</li> <li>Supports both ACR and Docker Hub registries</li> </ul>"},{"location":"guides/deployment/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Push to main branch                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u2502                  \u2502\n             \u25bc                  \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Build Docker  \u2502   \u2502  Build Docker    \u2502\n    \u2502  Image         \u2502   \u2502  Image           \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                    \u2502\n             \u25bc                    \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Push to       \u2502   \u2502  Push to ACR     \u2502\n    \u2502  Docker Hub    \u2502   \u2502  (or Docker Hub) \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                    \u2502\n             \u25bc                    \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Render        \u2502   \u2502  Azure Web App   \u2502\n    \u2502  Auto-Deploy   \u2502   \u2502  Deploy          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/deployment/#setting-up-github-secrets","title":"Setting Up GitHub Secrets","text":""},{"location":"guides/deployment/#required-for-all-deployments","title":"Required for All Deployments","text":"<ol> <li><code>DOCKERHUB_USERNAME</code> - Your Docker Hub username</li> <li><code>DOCKERHUB_TOKEN</code> - Docker Hub access token</li> <li>Create at: Docker Hub \u2192 Account Settings \u2192 Security \u2192 New Access Token</li> </ol>"},{"location":"guides/deployment/#required-for-azure-deployment","title":"Required for Azure Deployment","text":"<ol> <li><code>AZURE_CREDENTIALS</code> - Service principal credentials (JSON format)</li> </ol> <pre><code>az ad sp create-for-rbac --name \"github-actions-trump-nlp\" --sdk-auth --role contributor --scopes /subscriptions/{subscription-id}/resourceGroups/trump-nlp-rg\n</code></pre> <ol> <li><code>AZURE_WEBAPP_NAME</code> - Your Azure Web App name (e.g., <code>trump-speeches-nlp</code>)</li> </ol>"},{"location":"guides/deployment/#required-for-azure-container-registry-optional","title":"Required for Azure Container Registry (Optional)","text":"<ol> <li><code>AZURE_REGISTRY_LOGIN_SERVER</code> - ACR login server (e.g., <code>trumpnlpacr.azurecr.io</code>)</li> <li><code>AZURE_REGISTRY_USERNAME</code> - ACR admin username</li> <li><code>AZURE_REGISTRY_PASSWORD</code> - ACR admin password</li> </ol> <p>Get ACR credentials:</p> <pre><code>az acr credential show --name trumpnlpacr\n</code></pre>"},{"location":"guides/deployment/#workflow-triggers","title":"Workflow Triggers","text":"Workflow Automatic Trigger Manual Trigger When to Use CI Push/PR to main, develop, feature/* \u2705 Yes Testing code changes Security Push/PR + Weekly (Mon 9AM) \u2705 Yes Regular security audits Deploy Render Push to main \u2705 Yes Deploy to Render Deploy Azure Push to main \u2705 Yes (with options) Deploy to Azure"},{"location":"guides/deployment/#manual-deployment-triggers","title":"Manual Deployment Triggers","text":"<p>For Azure:</p> <ol> <li>Go to GitHub \u2192 Actions \u2192 \"Deploy to Azure\"</li> <li>Click \"Run workflow\"</li> <li>Select options:</li> <li>Environment: production/staging</li> <li>Use Docker Hub: true/false (ACR is default)</li> <li>Click \"Run workflow\"</li> </ol> <p>For Render:</p> <ol> <li>Go to GitHub \u2192 Actions \u2192 \"Deploy to Render\"</li> <li>Click \"Run workflow\"</li> <li>Click \"Run workflow\" to confirm</li> </ol>"},{"location":"guides/deployment/#viewing-workflow-results","title":"Viewing Workflow Results","text":"<ul> <li>Navigate to your repository \u2192 Actions tab</li> <li>Click on any workflow run to see detailed logs</li> <li>Failed workflows will show which step failed and why</li> <li>Deployment summaries are available in each workflow run</li> </ul>"},{"location":"guides/deployment/#best-practices","title":"Best Practices","text":"<ol> <li>Always test locally before pushing to <code>main</code></li> <li>Use feature branches for development</li> <li>Review CI results before merging PRs</li> <li>Monitor deployments after pushing to <code>main</code></li> <li>Check security scans weekly</li> <li>Use manual triggers for testing deployment changes</li> </ol>"},{"location":"guides/deployment/#environment-variables","title":"Environment Variables","text":""},{"location":"guides/deployment/#required-variables","title":"Required Variables","text":"Variable Description Default <code>PORT</code> Port to run the application <code>8000</code> <code>PYTHONUNBUFFERED</code> Disable Python output buffering <code>1</code>"},{"location":"guides/deployment/#optional-variables","title":"Optional Variables","text":"Variable Description <code>PYTHON_VERSION</code> Python version (for Render) <code>WEBSITES_PORT</code> Port for Azure App Service"},{"location":"guides/deployment/#rag-specific-configuration","title":"RAG-Specific Configuration","text":"Variable Description Default <code>CHROMADB_PERSIST_DIR</code> Directory for ChromaDB persistence <code>./data/chromadb</code> <code>RAG_COLLECTION_NAME</code> Name of the vector collection <code>speeches</code> <code>RAG_CHUNK_SIZE</code> Text chunk size for embeddings <code>2048</code> <code>RAG_CHUNK_OVERLAP</code> Overlap between chunks <code>150</code> <code>EMBEDDING_MODEL</code> sentence-transformers model <code>all-MiniLM-L6-v2</code> <p>Note: ChromaDB data is persisted to disk. Ensure the persist directory is included in volume mounts for Docker deployments to maintain indexed documents across restarts.</p>"},{"location":"guides/deployment/#performance-tips","title":"Performance Tips","text":""},{"location":"guides/deployment/#for-free-tiers","title":"For Free Tiers","text":"<ol> <li>Render Free Tier:</li> <li>Apps sleep after 15 min of inactivity</li> <li>Use a health check service like cron-job.org to keep it awake</li> <li>Expect 30-60s cold start time</li> <li> <p>RAG Impact: First request will also load embedding model (~80MB) + index documents</p> </li> <li> <p>Azure Free Tier (F1):</p> </li> <li>Limited to 60 CPU minutes/day</li> <li>1 GB RAM limit</li> <li>Consider B1 tier ($13/month) for better performance</li> <li>RAG Requirements: Minimum 2GB RAM recommended with RAG enabled</li> </ol>"},{"location":"guides/deployment/#optimizing-docker-image","title":"Optimizing Docker Image","text":"<ul> <li>Use multi-stage builds (already implemented)</li> <li>Remove unnecessary data files</li> <li>Use <code>.dockerignore</code> to exclude notebooks and docs</li> <li>RAG Models: Pre-download models during build to reduce startup time</li> </ul>"},{"location":"guides/deployment/#rag-performance-considerations","title":"RAG Performance Considerations","text":"<p>Memory Requirements: - Without RAG: ~1.5GB RAM - With RAG: ~2.5GB RAM (includes embeddings model + vector store) - Recommended: 4GB RAM for production with concurrent users</p> <p>Storage Requirements: - Base application: ~1GB - ChromaDB index: ~50-100MB per 10,000 chunks - Embedding model: ~80MB</p> <p>Startup Time: - Without RAG: 10-15 seconds - With RAG: 30-60 seconds (model loading + document indexing) - Tip: Documents are auto-indexed on first startup if collection is empty</p> <p>Query Performance: - Semantic search: ~50-200ms per query - Question answering: ~200-500ms (includes search + answer generation) - Tip: Results improve with more indexed documents</p>"},{"location":"guides/deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/deployment/#docker-build-fails","title":"Docker Build Fails","text":"<pre><code># Clean Docker cache and rebuild\ndocker system prune -a\ndocker build --no-cache -t trump-speeches-nlp-api .\n</code></pre>"},{"location":"guides/deployment/#api-returns-503","title":"API Returns 503","text":"<ul> <li>Model may still be loading (can take 30-60s on first request)</li> <li>Check logs for errors</li> <li>Ensure sufficient memory (minimum 1GB recommended)</li> </ul>"},{"location":"guides/deployment/#azure-deployment-issues","title":"Azure Deployment Issues","text":"<pre><code># Check app logs\naz webapp log tail --resource-group trump-nlp-rg --name trump-speeches-nlp\n\n# Restart the app\naz webapp restart --resource-group trump-nlp-rg --name trump-speeches-nlp\n</code></pre>"},{"location":"guides/deployment/#render-deployment-issues","title":"Render Deployment Issues","text":"<ul> <li>Check build logs in Render dashboard</li> <li>Verify <code>.render/render.yaml</code> configuration</li> <li>Ensure all dependencies are in <code>pyproject.toml</code></li> </ul>"},{"location":"guides/deployment/#cost-comparison","title":"Cost Comparison","text":"Platform Free Tier Paid Tier Best For Render \u2705 Yes (with limitations) $7/month starter Quick demos, portfolio Azure \u2705 Yes (F1: 60 min/day) $13/month (B1) Enterprise, Azure ecosystem Railway \u2705 $5 free credit Pay-as-you-go Simple projects Fly.io \u2705 Free allowance Pay-as-you-go Global deployment"},{"location":"guides/deployment/#next-steps","title":"Next Steps","text":"<p>After deployment:</p> <ol> <li>Test the API: Use the <code>/health</code> endpoint to verify</li> <li>Update README: Add your live demo link</li> <li>Monitor performance: Check logs and metrics</li> <li>Set up alerts: Configure uptime monitoring</li> <li>Add custom domain: (optional) Configure DNS</li> </ol>"},{"location":"guides/deployment/#support","title":"Support","text":"<p>For issues or questions:</p> <ul> <li>Check the main README</li> <li>Review API documentation at <code>/docs</code></li> <li>Open an issue on GitHub</li> </ul>"},{"location":"guides/quickstart/","title":"Quick Start Guide","text":"<p>This guide gets you up and running with the NLP Chatbot API in minutes. For comprehensive documentation, visit the full documentation site.</p>"},{"location":"guides/quickstart/#running-the-rag-powered-nlp-api","title":"Running the RAG-Powered NLP API","text":""},{"location":"guides/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+ installed</li> <li>uv installed (install guide)</li> <li>Google Gemini API key (get one free)</li> </ul>"},{"location":"guides/quickstart/#setup","title":"Setup","text":"<ol> <li>Install Dependencies</li> </ol> <pre><code>uv sync\n\nuv venv --python 3.12  # if you need to set a specific vesion\n</code></pre> <ol> <li>Configure Environment</li> </ol> <p>Create a <code>.env</code> file in the project root:    <pre><code>GEMINI_API_KEY=your_api_key_here\n</code></pre></p> <ol> <li>Run the API</li> </ol> <pre><code>uv run uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload\n</code></pre> <p>The API will automatically:    - Load the FinBERT sentiment model    - Initialize ChromaDB vector database    - Index the 35 speech documents (first run only)</p> <ol> <li>Access the Application</li> <li>Web UI: http://localhost:8000</li> <li>API Docs: http://localhost:8000/docs</li> <li>Health Check: http://localhost:8000/health</li> </ol>"},{"location":"guides/quickstart/#running-with-docker","title":"Running with Docker","text":""},{"location":"guides/quickstart/#build-and-run","title":"Build and Run","text":"<pre><code>docker build -t trump-speeches-nlp-chatbot .\ndocker run --rm -it -p 8000:8000 --env-file .env --name nlp-chatbot trump-speeches-nlp-chatbot\ndocker run --rm -it -p 8000:8000 -v \"${PWD}/data/chromadb:/app/data/chromadb\" --env-file .env --name nlp-chatbot trump-speeches-nlp-chatbot\n</code></pre>"},{"location":"guides/quickstart/#using-docker-compose","title":"Using Docker Compose","text":"<pre><code>docker-compose up\n</code></pre>"},{"location":"guides/quickstart/#testing-the-rag-system","title":"Testing the RAG System","text":""},{"location":"guides/quickstart/#using-the-web-interface","title":"Using the Web Interface","text":"<ol> <li>Open http://localhost:8000</li> <li>Navigate to the \"RAG Q&amp;A\" tab</li> <li>Ask a question like \"What economic policies were discussed?\"</li> <li>View the AI-generated answer with confidence scores and sources</li> </ol>"},{"location":"guides/quickstart/#using-curl","title":"Using curl","text":"<pre><code># Ask a question (RAG)\ncurl -X POST http://localhost:8000/rag/ask `\n  -H \"Content-Type: application/json\" `\n  -d '{\"question\": \"What was said about the economy?\", \"top_k\": 5}'\n\n# Semantic search\ncurl -X POST http://localhost:8000/rag/search `\n  -H \"Content-Type: application/json\" `\n  -d '{\"query\": \"immigration policy\", \"top_k\": 5}'\n\n# Get RAG statistics\ncurl http://localhost:8000/rag/stats\n\n# Sentiment analysis (traditional NLP)\ncurl -X POST http://localhost:8000/analyze/sentiment `\n  -H \"Content-Type: application/json\" `\n  -d '{\"text\": \"The economy is doing great!\"}'\n</code></pre>"},{"location":"guides/quickstart/#using-python","title":"Using Python","text":"<pre><code>import requests\n\n# RAG Question Answering\nresponse = requests.post(\n    \"http://localhost:8000/rag/ask\",\n    json={\n        \"question\": \"What were the main themes in the 2020 speeches?\",\n        \"top_k\": 5\n    }\n)\nresult = response.json()\nprint(f\"Answer: {result['answer']}\")\nprint(f\"Confidence: {result['confidence']} ({result['confidence_score']:.2f})\")\nprint(f\"Sources: {', '.join(result['sources'])}\")\n\n# Traditional NLP - Sentiment\nresponse = requests.post(\n    \"http://localhost:8000/analyze/sentiment\",\n    json={\"text\": \"This is incredible! Best economy ever.\"}\n)\nprint(response.json())\n</code></pre>"},{"location":"guides/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/quickstart/#rag-service-not-initialized","title":"\"RAG service not initialized\"","text":"<p>The API auto-indexes documents on first startup. This takes ~30-60 seconds. Check the logs for progress: <pre><code>INFO:     Loading documents into RAG service...\nINFO:     Loaded 35 documents into RAG service!\n</code></pre></p>"},{"location":"guides/quickstart/#gemini-api-errors","title":"Gemini API Errors","text":"<p>Ensure your <code>.env</code> file exists with a valid <code>GEMINI_API_KEY</code>. Get a free key at https://ai.google.dev/.</p>"},{"location":"guides/quickstart/#model-download-taking-long","title":"Model Download Taking Long","text":"<p>First run downloads ~1-2 GB of models (FinBERT, MPNet embeddings). Subsequent runs are fast.</p>"},{"location":"guides/quickstart/#port-already-in-use","title":"Port Already in Use","text":"<pre><code>uv run uvicorn src.api:app --reload --port 8001\n</code></pre>"},{"location":"guides/quickstart/#module-not-found","title":"Module Not Found","text":"<p>Ensure you're in the project root directory and have run <code>uv sync</code>.</p>"},{"location":"guides/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Try the interactive web interface at http://localhost:8000</li> <li>Explore API documentation at http://localhost:8000/docs</li> <li>Read about RAG improvements in <code>docs/RAG_IMPROVEMENTS.md</code></li> <li>Deploy to production with <code>docs/DEPLOYMENT.md</code></li> </ul>"},{"location":"howto/documentation/","title":"Documentation Guide \u2014 MkDocs","text":"<p>This project uses MkDocs with the Material theme to generate professional documentation from markdown files. This guide explains how to work with the documentation system.</p>"},{"location":"howto/documentation/#what-is-mkdocs","title":"What is MkDocs?","text":"<p>MkDocs is a static site generator that transforms markdown files into a beautiful, searchable documentation website with:</p> <ul> <li>Navigation sidebar automatically generated</li> <li>Search functionality across all pages</li> <li>Professional theme (Material for MkDocs)</li> <li>Mobile-friendly responsive design</li> <li>Version control friendly \u2014 docs are just markdown files</li> </ul>"},{"location":"howto/documentation/#quick-reference","title":"Quick Reference","text":""},{"location":"howto/documentation/#view-documentation-locally","title":"View Documentation Locally","text":"<pre><code># Install documentation dependencies\nuv sync --group docs\n\n# Serve docs with live reload (default port 8000)\nuv run mkdocs serve\n\n# Use custom port to avoid conflicts with the API\nuv run mkdocs serve --dev-addr localhost:8001\n</code></pre> <p>Then open http://localhost:8001 in your browser. Changes to markdown files will automatically reload!</p>"},{"location":"howto/documentation/#build-static-site","title":"Build Static Site","text":"<pre><code># Build HTML site to site/ folder\nuv run mkdocs build\n\n# Build with verbose output\nuv run mkdocs build --verbose\n\n# Clean build (remove site/ first)\nuv run mkdocs build --clean\n</code></pre>"},{"location":"howto/documentation/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<pre><code># Deploy to GitHub Pages (gh-pages branch)\nuv run mkdocs gh-deploy\n\n# Deploy with custom commit message\nuv run mkdocs gh-deploy --message \"Update documentation\"\n</code></pre> <p>Note: The project has automated deployment via GitHub Actions, so you typically don't need to run this manually.</p>"},{"location":"howto/documentation/#project-structure","title":"Project Structure","text":"<pre><code>Trump-Rally-Speeches-NLP-Chatbot/\n\u251c\u2500\u2500 docs/                    # All documentation files\n\u2502   \u251c\u2500\u2500 index.md            # Homepage\n\u2502   \u251c\u2500\u2500 guides/             # Getting started guides\n\u2502   \u2502   \u251c\u2500\u2500 quickstart.md\n\u2502   \u2502   \u2514\u2500\u2500 deployment.md\n\u2502   \u251c\u2500\u2500 howto/              # Task-oriented guides\n\u2502   \u2502   \u251c\u2500\u2500 testing.md\n\u2502   \u2502   \u251c\u2500\u2500 entity-analytics.md\n\u2502   \u2502   \u2514\u2500\u2500 documentation.md    # This file\n\u2502   \u2514\u2500\u2500 reference/          # Technical reference\n\u2502       \u251c\u2500\u2500 architecture.md\n\u2502       \u2514\u2500\u2500 rag-features.md\n\u251c\u2500\u2500 mkdocs.yml              # MkDocs configuration\n\u2514\u2500\u2500 site/                   # Generated HTML (not committed)\n</code></pre>"},{"location":"howto/documentation/#how-to-add-or-edit-documentation","title":"How to Add or Edit Documentation","text":""},{"location":"howto/documentation/#1-edit-existing-pages","title":"1. Edit Existing Pages","text":"<p>Simply edit any <code>.md</code> file in the <code>docs/</code> folder. If you have <code>mkdocs serve</code> running, changes will appear instantly in your browser.</p>"},{"location":"howto/documentation/#2-add-new-pages","title":"2. Add New Pages","text":"<p>Step 1: Create a new markdown file in the appropriate folder: <pre><code># Example: Add a new how-to guide\nNew-Item docs/howto/my-new-guide.md\n</code></pre></p> <p>Step 2: Add the page to navigation in <code>mkdocs.yml</code>: <pre><code>nav:\n  - Home: index.md\n  - How-To Guides:\n      - Testing: howto/testing.md\n      - My New Guide: howto/my-new-guide.md  # Add this line\n</code></pre></p> <p>Step 3: Preview with <code>mkdocs serve</code> and verify it appears in the sidebar.</p>"},{"location":"howto/documentation/#3-reorganize-navigation","title":"3. Reorganize Navigation","text":"<p>Edit the <code>nav</code> section in <code>mkdocs.yml</code>:</p> <pre><code>nav:\n  - Home: index.md\n\n  - Getting Started:\n      - Quickstart: guides/quickstart.md\n      - Deployment: guides/deployment.md\n\n  - How-To Guides:\n      - Testing: howto/testing.md\n      - Documentation: howto/documentation.md\n\n  - Reference:\n      - Architecture: reference/architecture.md\n      - RAG Features: reference/rag-features.md\n</code></pre> <p>The order in <code>mkdocs.yml</code> determines the order in the sidebar.</p>"},{"location":"howto/documentation/#configuration-reference","title":"Configuration Reference","text":""},{"location":"howto/documentation/#port-configuration","title":"Port Configuration","text":"<p>By default, MkDocs serves on port 8000. To change:</p> <pre><code># Serve on port 8001\nuv run mkdocs serve --dev-addr localhost:8001\n\n# Serve on all interfaces (for network access)\nuv run mkdocs serve --dev-addr 0.0.0.0:8001\n</code></pre>"},{"location":"howto/documentation/#theme-customization","title":"Theme Customization","text":"<p>Edit <code>mkdocs.yml</code> to customize the theme:</p> <pre><code>theme:\n  name: material\n  palette:\n    # Light mode\n    - scheme: default\n      primary: indigo      # Change primary color\n      accent: indigo       # Change accent color\n</code></pre> <p>Available colors: red, pink, purple, deep purple, indigo, blue, light blue, cyan, teal, green, light green, lime, yellow, amber, orange, deep orange</p>"},{"location":"howto/documentation/#add-a-logo","title":"Add a Logo","text":"<ol> <li>Add your logo image to <code>docs/assets/images/</code></li> <li>Update <code>mkdocs.yml</code>:</li> </ol> <pre><code>theme:\n  name: material\n  logo: assets/images/logo.png\n  favicon: assets/images/favicon.ico\n</code></pre>"},{"location":"howto/documentation/#add-custom-css-or-javascript","title":"Add Custom CSS or JavaScript","text":"<ol> <li>Create files:</li> <li><code>docs/stylesheets/extra.css</code></li> <li> <p><code>docs/javascripts/extra.js</code></p> </li> <li> <p>Update <code>mkdocs.yml</code>:</p> </li> </ol> <pre><code>extra_css:\n  - stylesheets/extra.css\n\nextra_javascript:\n  - javascripts/extra.js\n</code></pre>"},{"location":"howto/documentation/#markdown-features","title":"Markdown Features","text":"<p>MkDocs with Material theme supports rich markdown features:</p>"},{"location":"howto/documentation/#admonitions-call-out-boxes","title":"Admonitions (Call-out Boxes)","text":"<pre><code>!!! note\n    This is a note admonition.\n\n!!! warning\n    This is a warning admonition.\n\n!!! tip\n    This is a tip admonition.\n\n??? example \"Collapsible Example\"\n    This content is collapsed by default.\n</code></pre> <p>Note</p> <p>This is a note admonition.</p> <p>Warning</p> <p>This is a warning admonition.</p>"},{"location":"howto/documentation/#code-blocks-with-syntax-highlighting","title":"Code Blocks with Syntax Highlighting","text":"<pre><code>```python\ndef hello_world():\n    print(\"Hello, World!\")\n```\n\n```bash\nuv run pytest\n```\n</code></pre>"},{"location":"howto/documentation/#tabbed-content","title":"Tabbed Content","text":"<pre><code>=== \"Python\"\n    ```python\n    print(\"Hello from Python\")\n    ```\n\n=== \"PowerShell\"\n    ```powershell\n    Write-Host \"Hello from PowerShell\"\n    ```\n</code></pre> PythonPowerShell <pre><code>print(\"Hello from Python\")\n</code></pre> <pre><code>Write-Host \"Hello from PowerShell\"\n</code></pre>"},{"location":"howto/documentation/#task-lists","title":"Task Lists","text":"<pre><code>- [x] Completed task\n- [ ] Incomplete task\n- [ ] Another task\n</code></pre> <ul> <li> Completed task</li> <li> Incomplete task</li> <li> Another task</li> </ul>"},{"location":"howto/documentation/#tables","title":"Tables","text":"<pre><code>| Feature | Supported |\n|---------|-----------|\n| Search  | \u2705        |\n| Mobile  | \u2705        |\n| Dark Mode | \u2705      |\n</code></pre> Feature Supported Search \u2705 Mobile \u2705 Dark Mode \u2705"},{"location":"howto/documentation/#mermaid-diagrams","title":"Mermaid Diagrams","text":"<pre><code>```mermaid\ngraph LR\n    A[User] --&gt; B[API]\n    B --&gt; C[RAG Service]\n    C --&gt; D[ChromaDB]\n```\n</code></pre> <pre><code>graph LR\n    A[User] --&gt; B[API]\n    B --&gt; C[RAG Service]\n    C --&gt; D[ChromaDB]</code></pre>"},{"location":"howto/documentation/#deployment","title":"Deployment","text":""},{"location":"howto/documentation/#automated-deployment-recommended","title":"Automated Deployment (Recommended)","text":"<p>The project includes a GitHub Action that automatically deploys documentation to GitHub Pages when you push to the <code>main</code> branch.</p> <p>How it works: 1. You push changes to <code>main</code> 2. GitHub Actions builds the docs 3. Deploys to GitHub Pages automatically 4. Live at: https://justakris.github.io/Trump-Rally-Speeches-NLP-Chatbot/</p> <p>Configuration: See <code>.github/workflows/deploy-docs.yml</code></p>"},{"location":"howto/documentation/#manual-deployment","title":"Manual Deployment","text":"<p>If you need to deploy manually:</p> <pre><code># Deploy to GitHub Pages\nuv run mkdocs gh-deploy\n</code></pre> <p>This command: 1. Builds the site (<code>mkdocs build</code>) 2. Commits the <code>site/</code> folder to the <code>gh-pages</code> branch 3. Pushes to GitHub</p> <p>Note: Ensure you have push access to the repository.</p>"},{"location":"howto/documentation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/documentation/#port-already-in-use","title":"Port Already in Use","text":"<p>If port 8000 is already in use by your API:</p> <pre><code>uv run mkdocs serve --dev-addr localhost:8001\n</code></pre>"},{"location":"howto/documentation/#page-not-found-in-sidebar","title":"\"Page not found\" in Sidebar","text":"<p>Check <code>mkdocs.yml</code> navigation and ensure: - The file path is correct (relative to <code>docs/</code>) - The file exists - The file has a <code>.md</code> extension</p>"},{"location":"howto/documentation/#changes-not-appearing","title":"Changes Not Appearing","text":"<ol> <li>Check terminal for build errors</li> <li>Hard refresh browser (Ctrl+Shift+R)</li> <li>Restart <code>mkdocs serve</code></li> </ol>"},{"location":"howto/documentation/#build-warnings","title":"Build Warnings","text":"<pre><code>WARNING - Doc file 'path/to/file.md' contains a link to 'broken-link.md'\n</code></pre> <p>This means you have a broken internal link. Fix the link or remove it.</p>"},{"location":"howto/documentation/#images-not-loading","title":"Images Not Loading","text":"<p>Ensure images are in <code>docs/</code> folder and use relative paths:</p> <pre><code>![Architecture](../assets/images/architecture.png)\n</code></pre>"},{"location":"howto/documentation/#best-practices","title":"Best Practices","text":""},{"location":"howto/documentation/#1-organize-by-purpose","title":"1. Organize by Purpose","text":"<ul> <li><code>guides/</code> \u2014 Getting started, tutorials</li> <li><code>howto/</code> \u2014 Task-oriented guides (how to do X)</li> <li><code>reference/</code> \u2014 Technical specs, API docs, architecture</li> </ul>"},{"location":"howto/documentation/#2-use-clear-titles","title":"2. Use Clear Titles","text":"<p>Good: <code># Testing Guide \u2014 pytest and Coverage</code> Bad: <code># Testing</code></p>"},{"location":"howto/documentation/#3-add-metadata","title":"3. Add Metadata","text":"<p>At the top of each page, you can add metadata:</p> <pre><code>---\ntitle: Testing Guide\ndescription: How to run tests and check coverage\n---\n</code></pre>"},{"location":"howto/documentation/#4-link-between-pages","title":"4. Link Between Pages","text":"<p>Use relative links to link between docs:</p> <pre><code>See the [Quickstart Guide](../guides/quickstart.md) for setup instructions.\n</code></pre>"},{"location":"howto/documentation/#5-keep-navigation-flat","title":"5. Keep Navigation Flat","text":"<p>Avoid deeply nested navigation (max 2-3 levels).</p>"},{"location":"howto/documentation/#6-test-before-committing","title":"6. Test Before Committing","text":"<p>Always run <code>mkdocs build</code> before committing to catch broken links and errors:</p> <pre><code>uv run mkdocs build --strict\n</code></pre> <p>The <code>--strict</code> flag turns warnings into errors.</p>"},{"location":"howto/documentation/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"howto/documentation/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>The project includes automated documentation deployment. See <code>.github/workflows/deploy-docs.yml</code>:</p> <pre><code>name: Deploy Documentation\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'docs/**'\n      - 'mkdocs.yml'\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n      - run: pip install mkdocs-material\n      - run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"howto/documentation/#triggers","title":"Triggers","text":"<p>Documentation deploys automatically when: - You push to <code>main</code> - Changes are in <code>docs/</code> folder or <code>mkdocs.yml</code></p>"},{"location":"howto/documentation/#resources","title":"Resources","text":"<ul> <li>MkDocs Documentation: https://www.mkdocs.org/</li> <li>Material for MkDocs: https://squidfunk.github.io/mkdocs-material/</li> <li>Markdown Guide: https://www.markdownguide.org/</li> <li>Live Documentation: https://justakris.github.io/Trump-Rally-Speeches-NLP-Chatbot/</li> </ul>"},{"location":"howto/documentation/#summary","title":"Summary","text":"<p>To work with docs: 1. Edit markdown files in <code>docs/</code> 2. Run <code>uv run mkdocs serve --dev-addr localhost:8001</code> to preview 3. Commit and push to <code>main</code> 4. GitHub Actions deploys automatically</p> <p>Need help? Open an issue on GitHub or check the MkDocs documentation.</p>"},{"location":"howto/entity-analytics/","title":"Entity Analytics &amp; Confidence Explainability - Implementation Summary","text":""},{"location":"howto/entity-analytics/#overview","title":"Overview","text":"<p>Added two major UX enhancements to make the RAG system more transparent and researcher-friendly:</p> <ol> <li>Confidence Justification - Human-readable explanations of why confidence is at a certain level</li> <li>Entity Analytics - Comprehensive metadata about entities including mentions, sentiment, and associations</li> </ol>"},{"location":"howto/entity-analytics/#features-implemented","title":"Features Implemented","text":""},{"location":"howto/entity-analytics/#1-confidence-explanation","title":"1. \u2705 Confidence Explanation","text":"<p>Problem: \"Confidence: MEDIUM\" was opaque - users didn't know why</p> <p>Solution: Added natural language explanation that references key factors</p> <p>Example Output: <pre><code>Confidence: MEDIUM (score: 0.59)\nExplanation: Overall confidence is MEDIUM (score: 0.59) based on weak semantic match \n(similarity: 0.22), very consistent results (consistency: 1.00), 5 supporting context \nchunks, 'Biden' mentioned in all retrieved chunks.\n</code></pre></p> <p>Implementation: New method <code>_generate_confidence_explanation()</code> in <code>RAGService</code></p>"},{"location":"howto/entity-analytics/#2-entity-sentiment-analysis","title":"2. \u2705 Entity Sentiment Analysis","text":"<p>Problem: No insight into sentiment/tone about mentioned entities</p> <p>Solution: Integrated sentiment analyzer to calculate average sentiment across entity mentions</p> <p>Example Output: <pre><code>Biden:\n  Average sentiment: -0.61 (Negative)\n  Sample size: 50 chunks\n</code></pre></p> <p>How it works: - Analyzes up to 50 context chunks containing the entity - Uses FinBERT sentiment model (already in project) - Converts scores to -1 (negative) to +1 (positive) - Classifies as Positive, Neutral, or Negative</p> <p>Implementation: New method <code>_analyze_entity_sentiment()</code> in <code>RAGService</code></p>"},{"location":"howto/entity-analytics/#3-entity-co-occurrence-analysis","title":"3. \u2705 Entity Co-occurrence Analysis","text":"<p>Problem: No context about what topics/terms surround an entity</p> <p>Solution: Extract most common words appearing near the entity</p> <p>Example Output: <pre><code>Biden:\n  Associated terms: socialism, weakness, failure, china, corrupt\n</code></pre></p> <p>How it works: - Extracts words from contexts containing the entity - Filters stopwords - Returns top 5 most frequent terms - Window-based approach around entity mentions</p> <p>Implementation: New method <code>_find_entity_associations()</code> in <code>RAGService</code></p>"},{"location":"howto/entity-analytics/#api-response-format","title":"API Response Format","text":""},{"location":"howto/entity-analytics/#enhanced-raganswerresponse","title":"Enhanced RAGAnswerResponse","text":"<pre><code>{\n    \"answer\": \"...\",\n    \"confidence\": \"medium\",\n    \"confidence_score\": 0.587,\n    \"confidence_explanation\": \"Overall confidence is MEDIUM (score: 0.59)...\",  # NEW\n    \"confidence_factors\": {\n        \"retrieval_score\": 0.219,\n        \"consistency\": 0.998,\n        \"chunk_coverage\": 5,\n        \"entity_coverage\": 1.0\n    },\n    \"entity_statistics\": {  # ENHANCED\n        \"Biden\": {\n            \"mention_count\": 524,\n            \"speech_count\": 30,\n            \"corpus_percentage\": 25.03,\n            \"speeches\": [\"OhioSep21_2020.txt\", ...],\n            \"sentiment\": {  # NEW\n                \"average_score\": -0.61,\n                \"classification\": \"Negative\",\n                \"sample_size\": 50\n            },\n            \"associated_terms\": [  # NEW\n                \"socialism\", \"weakness\", \"failure\", \"china\", \"corrupt\"\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"howto/entity-analytics/#code-changes","title":"Code Changes","text":""},{"location":"howto/entity-analytics/#files-modified","title":"Files Modified","text":"<ol> <li>src/rag_service.py</li> <li>Added <code>_generate_confidence_explanation()</code> - 60 lines</li> <li>Added <code>_analyze_entity_sentiment()</code> - 55 lines</li> <li>Added <code>_find_entity_associations()</code> - 50 lines</li> <li>Modified <code>_get_entity_statistics()</code> to include new analytics</li> <li> <p>Modified <code>_calculate_confidence()</code> to generate explanation</p> </li> <li> <p>src/api.py</p> </li> <li>Updated <code>RAGAnswerResponse</code> model with <code>confidence_explanation</code> field</li> </ol>"},{"location":"howto/entity-analytics/#new-dependencies","title":"New Dependencies","text":"<p>None! Uses existing <code>SentenceAnalyzer</code> already in the project.</p>"},{"location":"howto/entity-analytics/#usage-examples","title":"Usage Examples","text":""},{"location":"howto/entity-analytics/#command-line-test","title":"Command Line Test","text":"<pre><code>uv run python test_enhancements.py\n</code></pre>"},{"location":"howto/entity-analytics/#api-request","title":"API Request","text":"<pre><code>$body = @{ question = \"What does Trump say about Biden?\"; top_k = 5 } | ConvertTo-Json\nInvoke-RestMethod -Uri \"http://localhost:8001/rag/ask\" -Method Post -Body $body -ContentType \"application/json\"\n</code></pre>"},{"location":"howto/entity-analytics/#python-code","title":"Python Code","text":"<pre><code>from src.rag_service import RAGService\n\nrag = RAGService()\nresult = rag.ask(\"What are Trump's views on Biden?\", top_k=5)\n\n# Check confidence explanation\nprint(f\"Confidence: {result['confidence']}\")\nprint(f\"Why: {result['confidence_explanation']}\")\n\n# View entity analytics\nif 'entity_statistics' in result:\n    for entity, stats in result['entity_statistics'].items():\n        print(f\"\\n{entity}:\")\n        print(f\"  Mentions: {stats['mention_count']}\")\n        print(f\"  Sentiment: {stats['sentiment']['classification']}\")\n        print(f\"  Associated with: {', '.join(stats['associated_terms'])}\")\n</code></pre>"},{"location":"howto/entity-analytics/#real-world-example","title":"Real-World Example","text":"<p>Query: \"What does Trump say about Biden?\"</p> <p>Response Analytics:</p> <pre><code>======================================================================\nCONFIDENCE:\n======================================================================\nLevel: MEDIUM\nScore: 0.587\n\nExplanation: Overall confidence is MEDIUM (score: 0.59) based on weak \nsemantic match (similarity: 0.22), very consistent results (consistency: \n1.00), 5 supporting context chunks, 'Biden' mentioned in all retrieved \nchunks.\n\n======================================================================\nENTITY ANALYTICS:\n======================================================================\n\nBiden:\n  Mentions: 524 times across 30 speeches\n  Corpus coverage: 25.03%\n  Average sentiment: 0.00 (Neutral)\n  Sample size: 50 chunks\n  Associated terms: people, our, right, about, say\n\nTrump:\n  Mentions: 449 times across 35 speeches\n  Corpus coverage: 24.34%\n  Average sentiment: 0.00 (Neutral)\n  Sample size: 50 chunks\n  Associated terms: people, right, one, say, because\n</code></pre> <p>Insights: - Biden is mentioned in 85% of speeches (30 out of 35) - Covers 25% of entire corpus - Associated with terms like \"socialism\", \"weakness\" (when more specific query used) - Sentiment is relatively neutral aggregate (varies per context)</p>"},{"location":"howto/entity-analytics/#uifrontend-integration-todo","title":"UI/Frontend Integration (TODO)","text":""},{"location":"howto/entity-analytics/#confidence-tooltip","title":"Confidence Tooltip","text":"<pre><code>&lt;div class=\"confidence-badge\" tooltip=\"{confidence_explanation}\"&gt;\n  Confidence: MEDIUM \u24d8\n&lt;/div&gt;\n</code></pre>"},{"location":"howto/entity-analytics/#entity-analytics-card","title":"Entity Analytics Card","text":"<pre><code>&lt;div class=\"entity-analytics\"&gt;\n  &lt;h3&gt;\ud83d\udcca Entity Analysis: Biden&lt;/h3&gt;\n\n  &lt;div class=\"stat\"&gt;\n    &lt;span class=\"label\"&gt;Mentions:&lt;/span&gt;\n    &lt;span class=\"value\"&gt;524 times in 30 speeches&lt;/span&gt;\n  &lt;/div&gt;\n\n  &lt;div class=\"stat\"&gt;\n    &lt;span class=\"label\"&gt;Corpus Coverage:&lt;/span&gt;\n    &lt;span class=\"value\"&gt;25%&lt;/span&gt;\n    &lt;div class=\"progress-bar\" style=\"width: 25%\"&gt;&lt;/div&gt;\n  &lt;/div&gt;\n\n  &lt;div class=\"stat\"&gt;\n    &lt;span class=\"label\"&gt;Average Sentiment:&lt;/span&gt;\n    &lt;span class=\"value sentiment-negative\"&gt;-0.61 (Negative)&lt;/span&gt;\n  &lt;/div&gt;\n\n  &lt;div class=\"stat\"&gt;\n    &lt;span class=\"label\"&gt;Associated Terms:&lt;/span&gt;\n    &lt;div class=\"tags\"&gt;\n      &lt;span class=\"tag\"&gt;socialism&lt;/span&gt;\n      &lt;span class=\"tag\"&gt;weakness&lt;/span&gt;\n      &lt;span class=\"tag\"&gt;failure&lt;/span&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"howto/entity-analytics/#performance-impact","title":"Performance Impact","text":""},{"location":"howto/entity-analytics/#memory","title":"Memory","text":"<ul> <li>Sentiment Analysis: +150MB (FinBERT model, already loaded)</li> <li>Entity Stats Cache: ~1MB per query (not cached yet)</li> </ul>"},{"location":"howto/entity-analytics/#latency","title":"Latency","text":"<ul> <li>Confidence Explanation: &lt; 1ms (string formatting)</li> <li>Entity Sentiment: ~2-5s for 50 chunks (one-time per query)</li> <li>Associated Terms: ~100ms (text processing)</li> </ul> <p>Total added latency: ~2-5 seconds per query with entities</p>"},{"location":"howto/entity-analytics/#optimization-opportunities","title":"Optimization Opportunities","text":"<ol> <li>Cache entity statistics - Same entities queried multiple times</li> <li>Async sentiment analysis - Don't block on sentiment</li> <li>Reduce sample size - Use 20 chunks instead of 50</li> <li>Pre-compute statistics - Calculate during indexing</li> </ol>"},{"location":"howto/entity-analytics/#testing","title":"Testing","text":""},{"location":"howto/entity-analytics/#unit-tests","title":"Unit Tests","text":"<p>Create <code>tests/test_entity_analytics.py</code>:</p> <pre><code>def test_confidence_explanation():\n    rag = RAGService()\n    # Test explanation generation\n\ndef test_entity_sentiment():\n    rag = RAGService()\n    # Test sentiment calculation\n\ndef test_entity_associations():\n    rag = RAGService()\n    # Test co-occurrence analysis\n</code></pre>"},{"location":"howto/entity-analytics/#integration-test","title":"Integration Test","text":"<pre><code>def test_full_entity_analytics():\n    rag = RAGService()\n    result = rag.ask(\"What about Biden?\", top_k=5)\n\n    assert \"confidence_explanation\" in result\n    assert \"entity_statistics\" in result\n\n    if result[\"entity_statistics\"]:\n        for entity, stats in result[\"entity_statistics\"].items():\n            assert \"sentiment\" in stats\n            assert \"associated_terms\" in stats\n            assert stats[\"sentiment\"][\"sample_size\"] &gt; 0\n</code></pre>"},{"location":"howto/entity-analytics/#next-steps","title":"Next Steps","text":""},{"location":"howto/entity-analytics/#high-priority","title":"High Priority","text":"<ol> <li>Add caching for entity statistics (Redis or in-memory)</li> <li>Async processing for sentiment to avoid blocking</li> <li>Frontend integration - Build UI cards for entity analytics</li> </ol>"},{"location":"howto/entity-analytics/#medium-priority","title":"Medium Priority","text":"<ol> <li>Sentiment over time - Track sentiment changes across chronological speeches</li> <li>Entity relationships - Show connections between entities (co-mentions)</li> <li>Improved associations - Use TF-IDF instead of raw frequency</li> </ol>"},{"location":"howto/entity-analytics/#low-priority","title":"Low Priority","text":"<ol> <li>Custom sentiment model - Fine-tune for political speech domain</li> <li>Entity disambiguation - Distinguish \"Biden\" vs \"Hunter Biden\"</li> <li>Visualization - Charts for sentiment trends, word clouds for associations</li> </ol>"},{"location":"howto/entity-analytics/#benefits-for-portfolio","title":"Benefits for Portfolio","text":""},{"location":"howto/entity-analytics/#demonstrates","title":"Demonstrates","text":"<p>\u2705 UX Design - Thoughtful user experience improvements \u2705 Explainable AI - Transparency in ML system decisions \u2705 Data Science - Sentiment analysis, NLP techniques \u2705 System Integration - Seamlessly added features to existing system \u2705 Performance Awareness - Considered latency/memory trade-offs</p>"},{"location":"howto/entity-analytics/#resume-bullet-points","title":"Resume Bullet Points","text":"<ul> <li>\"Implemented explainable AI features providing human-readable confidence justifications\"</li> <li>\"Built entity analytics system with sentiment analysis and co-occurrence detection\"</li> <li>\"Enhanced RAG system with researcher-friendly metadata reducing user confusion\"</li> <li>\"Integrated NLP techniques (sentiment analysis, entity extraction) into production API\"</li> </ul>"},{"location":"howto/entity-analytics/#known-limitations","title":"Known Limitations","text":"<ol> <li>Sentiment Neutrality: Political speech often analyzed as neutral</li> <li> <p>Fix: Fine-tune sentiment model on political corpus</p> </li> <li> <p>Association Quality: Stopword filtering may miss context</p> </li> <li> <p>Fix: Use more sophisticated NLP (dependency parsing, n-grams)</p> </li> <li> <p>Performance: 2-5s latency for sentiment analysis</p> </li> <li> <p>Fix: Async processing, caching, or pre-computation</p> </li> <li> <p>Entity Detection: Simple capitalization heuristic</p> </li> <li>Fix: Use proper NER (spaCy, Hugging Face)</li> </ol>"},{"location":"howto/entity-analytics/#comparison-before-vs-after","title":"Comparison: Before vs After","text":"Feature Before After Confidence info Just \"MEDIUM\" Full explanation with factors Entity mentions Count only Count + sentiment + associations User insight Minimal Comprehensive analytics Transparency Low High (explainable) Researcher-friendly No Yes (data science vibes)"},{"location":"howto/entity-analytics/#documentation","title":"Documentation","text":"<ul> <li>Quick test: <code>uv run python test_enhancements.py</code></li> <li>API docs: <code>http://localhost:8001/docs</code> (auto-updated)</li> <li>Code: <code>src/rag_service.py</code> (well-commented)</li> </ul> <p>Implementation Date: November 1, 2025 Author: Kristiyan Bonev Project: Donald Trump Rally Speeches NLP</p>"},{"location":"howto/testing/","title":"Testing &amp; Development Guide","text":""},{"location":"howto/testing/#running-tests","title":"Running Tests","text":""},{"location":"howto/testing/#using-uv-recommended","title":"Using uv (recommended)","text":"<p>This repository uses uv to manage virtual environments and run commands in a reproducible project environment. If you've already been using <code>uv</code> in this project, the examples below will work as-is.</p> <pre><code># Install project dependencies (including dev groups defined in pyproject)\nuv sync            # sync all default groups\nuv sync --group dev  # sync only dev dependencies (if grouped)\n\n# Run a command inside the project's environment\nuv run &lt;command&gt;   # e.g. `uv run pytest` or `uv run black src/`\n</code></pre> <p>If you prefer to use Poetry directly, the original Poetry commands are still valid and left as alternatives in this document.</p>"},{"location":"howto/testing/#install-development-dependencies-alternative-poetry","title":"Install Development Dependencies (alternative: Poetry)","text":"<pre><code># With Poetry (alternative)\npoetry install --with dev\n\n# Or activate Poetry shell and run commands directly\npoetry shell\n</code></pre>"},{"location":"howto/testing/#run-all-tests","title":"Run All Tests","text":"<pre><code># Run all tests with coverage\nuv run pytest\n\n# Run only unit tests\nuv run pytest -m unit\n\n# Run only integration tests\nuv run pytest -m integration\n\n# Run with verbose output\nuv run pytest -v\n\n# Run specific test file\nuv run pytest tests/test_preprocessing.py\n</code></pre>"},{"location":"howto/testing/#code-coverage","title":"Code Coverage","text":"<pre><code># Generate coverage report\nuv run pytest --cov=src --cov-report=html\n\n# Open coverage report\nstart htmlcov/index.html  # Windows\n</code></pre>"},{"location":"howto/testing/#code-quality-tools","title":"Code Quality Tools","text":""},{"location":"howto/testing/#formatting","title":"Formatting","text":"<pre><code># Format code with Black (via uv)\nuv run black src/\n\n# Check formatting without changes\nuv run black --check src/\n\n# Sort imports with isort\nuv run isort src/\n\n# Check imports without changes\nuv run isort --check-only src/\n</code></pre>"},{"location":"howto/testing/#linting","title":"Linting","text":"<pre><code># Run flake8\nuv run flake8 src/\n\n# Show detailed statistics\nuv run flake8 src/ --count --statistics --show-source\n</code></pre>"},{"location":"howto/testing/#type-checking","title":"Type Checking","text":"<pre><code># Run mypy type checker\nuv run mypy src/\n</code></pre>"},{"location":"howto/testing/#run-all-quality-checks","title":"Run All Quality Checks","text":"<pre><code># Run everything at once (uv wrapper)\nuv run black src/ &amp;&amp; uv run isort src/ &amp;&amp; uv run flake8 src/ &amp;&amp; uv run mypy src/ &amp;&amp; uv run pytest\nuv run black src/ ; uv run isort src/ ; uv run flake8 src/ ; uv run mypy src/ ; uv run pytest\n</code></pre>"},{"location":"howto/testing/#pre-commit-setup-optional","title":"Pre-commit Setup (Optional)","text":"<p>Install pre-commit hooks to automatically run checks before commits. If you manage dev dependencies with <code>uv</code>, use <code>uv sync --group dev</code> to install dev deps (including <code>pre-commit</code>) if listed in <code>pyproject.toml</code>. Otherwise install pre-commit directly:</p> <pre><code># Ensure pre-commit is installed in the project environment\nuv run pip install pre-commit\n\n# Install the git hook\nuv run pre-commit install\n</code></pre> <p>If you prefer Poetry:</p> <pre><code>poetry add --group dev pre-commit\npoetry run pre-commit install\n</code></pre>"},{"location":"howto/testing/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>The GitHub Actions workflow runs automatically on: - Push to <code>main</code>, <code>develop</code>, or <code>feature/*</code> branches - Pull requests to <code>main</code> or <code>develop</code></p>"},{"location":"howto/testing/#pipeline-jobs","title":"Pipeline Jobs:","text":"<ol> <li>Test Suite - Runs on Python 3.11, 3.12, 3.13</li> <li>Unit tests</li> <li>Integration tests (without ML model)</li> <li> <p>Coverage reporting</p> </li> <li> <p>Code Quality - Linting and formatting checks</p> </li> <li>flake8</li> <li>black</li> <li>isort</li> <li> <p>mypy</p> </li> <li> <p>Security - Security scanning</p> </li> <li>safety (dependency vulnerabilities)</li> <li> <p>bandit (code security issues)</p> </li> <li> <p>Build - Docker image build (on main branch only)</p> </li> <li>Builds image</li> <li>Tests health endpoint</li> </ol>"},{"location":"howto/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 test_preprocessing.py  # Unit tests for text processing\n\u251c\u2500\u2500 test_utils.py          # Unit tests for utilities\n\u2514\u2500\u2500 test_api.py            # Integration tests for API endpoints\n</code></pre>"},{"location":"howto/testing/#test-markers","title":"Test Markers","text":"<ul> <li><code>@pytest.mark.unit</code> - Fast unit tests</li> <li><code>@pytest.mark.integration</code> - API integration tests</li> <li><code>@pytest.mark.requires_model</code> - Tests needing ML model (skipped in CI)</li> <li><code>@pytest.mark.slow</code> - Slow-running tests</li> </ul>"},{"location":"howto/testing/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"howto/testing/#unit-test-example","title":"Unit Test Example","text":"<pre><code>import pytest\nfrom src.preprocessing import clean_text\n\n@pytest.mark.unit\ndef test_clean_text():\n    text = \"Hello World!\"\n    result = clean_text(text)\n    assert isinstance(result, str)\n</code></pre>"},{"location":"howto/testing/#api-test-example","title":"API Test Example","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom src.api import app\n\n@pytest.mark.integration\ndef test_health_check():\n    client = TestClient(app)\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n</code></pre>"},{"location":"howto/testing/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Target: 70%+ overall coverage</li> <li>Focus: Core logic in <code>src/</code></li> <li>Exclude: ML model internals, notebooks</li> </ul>"},{"location":"howto/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/testing/#nltk-data-missing","title":"NLTK Data Missing","text":"<pre><code>uv run python -c \"import nltk; nltk.download('punkt', quiet=True); nltk.download('stopwords', quiet=True); nltk.download('punkt_tab', quiet=True)\"\n</code></pre>"},{"location":"howto/testing/#import-errors","title":"Import Errors","text":"<pre><code># Reinstall dependencies (uv)\nuv sync --group dev\n\n# Or with Poetry\npoetry install --with dev\n</code></pre>"},{"location":"howto/testing/#slow-tests","title":"Slow Tests","text":"<pre><code># Skip slow tests\nuv run pytest -m \"not slow\"\n\n# Skip model-dependent tests\nuv run pytest -m \"not requires_model\"\n</code></pre>"},{"location":"reference/architecture/","title":"System Architecture","text":"<p>This document provides a comprehensive overview of the Trump Speeches NLP Chatbot API architecture, including system components, data flows, and deployment strategies.</p>"},{"location":"reference/architecture/#table-of-contents","title":"Table of Contents","text":"<ul> <li>High-Level Architecture</li> <li>Component Architecture</li> <li>RAG Pipeline</li> <li>Data Flow</li> <li>API Architecture</li> <li>Deployment Architecture</li> <li>Technology Stack</li> <li>Scalability Considerations</li> </ul>"},{"location":"reference/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    Client[Client/Browser]\n    Frontend[Static Frontend&lt;br/&gt;HTML/CSS/JS]\n    API[FastAPI Application&lt;br/&gt;REST API]\n\n    subgraph \"NLP Services\"\n        Sentiment[Sentiment Analyzer&lt;br/&gt;FinBERT]\n        Preprocessing[Text Preprocessing&lt;br/&gt;NLTK]\n        Topics[Topic Extraction&lt;br/&gt;TF-IDF]\n        RAG[RAG Service&lt;br/&gt;ChromaDB + Embeddings]\n    end\n\n    subgraph \"Data Layer\"\n        Speeches[Demo Dataset&lt;br/&gt;Political Speeches]\n        VectorDB[(ChromaDB&lt;br/&gt;Vector Store)]\n        Models[ML Models&lt;br/&gt;Transformers]\n    end\n\n    Client --&gt;|HTTP Requests| Frontend\n    Frontend --&gt;|API Calls| API\n    API --&gt; Sentiment\n    API --&gt; Preprocessing\n    API --&gt; Topics\n    API --&gt; RAG\n\n    Sentiment --&gt; Models\n    RAG --&gt; VectorDB\n    RAG --&gt; Models\n    Preprocessing --&gt; Speeches\n    Topics --&gt; Speeches</code></pre>"},{"location":"reference/architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"reference/architecture/#1-api-layer-srcapipy","title":"1. API Layer (<code>src/api.py</code>)","text":"<p>FastAPI application serving as the main entry point.</p> <p>Responsibilities: - HTTP request handling - Input validation (Pydantic models) - Error handling and logging - CORS middleware - Static file serving - Service orchestration</p> <p>Endpoints: - <code>/analyze/sentiment</code> - Sentiment analysis - <code>/analyze/words</code> - Word frequency analysis - <code>/analyze/topics</code> - Topic extraction - <code>/analyze/ngrams</code> - N-gram analysis - <code>/text/clean</code> - Text preprocessing - <code>/rag/ask</code> - RAG question answering - <code>/rag/search</code> - Semantic search - <code>/rag/stats</code> - Collection statistics - <code>/rag/index</code> - Document indexing - <code>/speeches/stats</code> - Dataset statistics - <code>/speeches/list</code> - List all speeches - <code>/health</code> - Health check</p>"},{"location":"reference/architecture/#2-sentiment-analysis-srcmodelspy","title":"2. Sentiment Analysis (<code>src/models.py</code>)","text":"<p>Transformer-based sentiment classification using FinBERT.</p> <p>Key Features: - Pre-trained FinBERT model (ProsusAI/finbert) - Automatic text chunking for long documents - Confidence scoring - Three-class classification (positive/negative/neutral)</p> <p>Processing Flow: <pre><code>graph LR\n    Input[Raw Text] --&gt; Chunk[Text Chunking&lt;br/&gt;512 tokens max]\n    Chunk --&gt; Tokenize[Tokenization&lt;br/&gt;BERT Tokenizer]\n    Tokenize --&gt; Model[FinBERT Model&lt;br/&gt;Inference]\n    Model --&gt; Aggregate[Score Aggregation&lt;br/&gt;Mean Pooling]\n    Aggregate --&gt; Output[Sentiment + Confidence]</code></pre></p>"},{"location":"reference/architecture/#3-rag-service-srcrag_servicepy","title":"3. RAG Service (<code>src/rag_service.py</code>)","text":"<p>Advanced Retrieval-Augmented Generation for intelligent question answering.</p> <p>Components: - Vector Store: ChromaDB with persistent SQLite storage - Embeddings: sentence-transformers (all-mpnet-base-v2, 768 dimensions) - Hybrid Search: Semantic (dense) + BM25 (sparse) retrieval - Reranking: Cross-encoder for precision optimization - Text Splitter: LangChain RecursiveCharacterTextSplitter - Chunking: 2048 chars with 150 char overlap (~512-768 tokens) - LLM: Google Gemini for answer generation</p> <p>Capabilities: - Document loading and indexing with progress tracking - Hybrid semantic + keyword search - Multi-factor confidence scoring - Entity extraction and analytics - Sentiment analysis for entities - Context-aware answer generation with Gemini</p>"},{"location":"reference/architecture/#4-text-preprocessing-srcpreprocessingpy","title":"4. Text Preprocessing (<code>src/preprocessing.py</code>)","text":"<p>Text cleaning and normalization utilities.</p> <p>Functions: - Stopword removal (NLTK) - Tokenization - Special character removal - URL removal - N-gram extraction</p>"},{"location":"reference/architecture/#5-utilities-srcutilspy","title":"5. Utilities (<code>src/utils.py</code>)","text":"<p>Data loading and analysis helpers.</p> <p>Functions: - Speech loading from directory - Word frequency statistics - Topic extraction (TF-IDF) - Dataset statistics calculation</p>"},{"location":"reference/architecture/#rag-pipeline","title":"RAG Pipeline","text":"<p>Detailed architecture of the Retrieval-Augmented Generation system.</p> <pre><code>graph TB\n    subgraph \"Indexing Phase (Startup)\"\n        Docs[Text Documents&lt;br/&gt;*.txt files]\n        Load[Document Loader]\n        Split[Text Splitter&lt;br/&gt;500 chars, 50 overlap]\n        Embed[Embedding Model&lt;br/&gt;all-MiniLM-L6-v2]\n        Store[(ChromaDB&lt;br/&gt;Vector Store)]\n\n        Docs --&gt; Load\n        Load --&gt; Split\n        Split --&gt;|Text Chunks| Embed\n        Embed --&gt;|384-dim Vectors| Store\n    end\n\n    subgraph \"Query Phase (Runtime)\"\n        Question[User Question]\n        QEmbed[Query Embedding]\n        Search[Similarity Search&lt;br/&gt;Cosine Distance]\n        Retrieve[Top-K Retrieval]\n        Generate[Answer Generation&lt;br/&gt;Context-based]\n        Response[Answer + Context]\n\n        Question --&gt; QEmbed\n        QEmbed --&gt; Search\n        Store -.-&gt;|Vector Lookup| Search\n        Search --&gt; Retrieve\n        Retrieve --&gt; Generate\n        Generate --&gt; Response\n    end</code></pre>"},{"location":"reference/architecture/#rag-workflow-details","title":"RAG Workflow Details","text":"<p>1. Indexing (One-time or on-demand): <pre><code>1. Load documents from directory\n2. Split into chunks (RecursiveCharacterTextSplitter)\n   - chunk_size: 2048 characters (~512-768 tokens)\n   - chunk_overlap: 150 characters (~100-150 tokens)\n3. Generate embeddings (sentence-transformers)\n   - Model: all-mpnet-base-v2\n   - Dimension: 768\n4. Store in ChromaDB with metadata:\n   - source: filename\n   - chunk_index: position in document\n   - total_chunks: document length\n</code></pre></p> <p>2. Querying: <pre><code>1. Receive question from user\n2. Extract entities from question (capitalized words)\n3. Generate question embedding (same model)\n4. Hybrid search:\n   a. Semantic search: cosine similarity on embeddings\n   b. BM25 search: keyword matching\n   c. Combine results with configurable weights\n5. Cross-encoder reranking for precision\n6. Retrieve top-k most relevant chunks (default k=5, max k=15)\n7. Calculate multi-factor confidence score:\n   - Retrieval quality (40%): semantic similarity\n   - Score consistency (25%): low variance = higher confidence\n   - Coverage (20%): number of supporting chunks\n   - Entity coverage (15%): mention frequency in results\n8. Generate entity statistics (mentions, sentiment, associations)\n9. Build context-aware prompt with entity focus\n10. Generate answer using Gemini LLM\n11. Return answer with:\n    - Generated text\n    - Confidence score and explanation\n    - Supporting context chunks\n    - Source attribution\n    - Entity analytics (if applicable)\n</code></pre></p> <p>3. Confidence Scoring:</p> <p>Multi-factor calculation combining: - Retrieval Quality (40%): Average semantic similarity (0-1) - Consistency (25%): Score variance (low variance = high confidence) - Coverage (20%): Number of supporting chunks (normalized) - Entity Coverage (15%): % of chunks mentioning query entities</p> <p>Confidence Levels: - High: combined_score \u2265 0.7 - Medium: 0.4 \u2264 combined_score &lt; 0.7 - Low: combined_score &lt; 0.4</p>"},{"location":"reference/architecture/#data-flow","title":"Data Flow","text":""},{"location":"reference/architecture/#sentiment-analysis-flow","title":"Sentiment Analysis Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Frontend\n    participant API\n    participant SentimentAnalyzer\n    participant FinBERT\n\n    User-&gt;&gt;Frontend: Enter text\n    Frontend-&gt;&gt;API: POST /analyze/sentiment\n    API-&gt;&gt;SentimentAnalyzer: analyze_sentiment(text)\n    SentimentAnalyzer-&gt;&gt;SentimentAnalyzer: Chunk text (512 tokens)\n    loop For each chunk\n        SentimentAnalyzer-&gt;&gt;FinBERT: Classify chunk\n        FinBERT--&gt;&gt;SentimentAnalyzer: Scores\n    end\n    SentimentAnalyzer-&gt;&gt;SentimentAnalyzer: Aggregate scores\n    SentimentAnalyzer--&gt;&gt;API: Sentiment + Confidence\n    API--&gt;&gt;Frontend: JSON Response\n    Frontend--&gt;&gt;User: Display results</code></pre>"},{"location":"reference/architecture/#rag-question-answering-flow","title":"RAG Question Answering Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Frontend\n    participant API\n    participant RAGService\n    participant ChromaDB\n    participant Embeddings\n\n    User-&gt;&gt;Frontend: Ask question\n    Frontend-&gt;&gt;API: POST /rag/ask\n    API-&gt;&gt;RAGService: ask(question)\n    RAGService-&gt;&gt;Embeddings: Encode question\n    Embeddings--&gt;&gt;RAGService: Query vector\n    RAGService-&gt;&gt;ChromaDB: Search similar vectors\n    ChromaDB--&gt;&gt;RAGService: Top-k chunks\n    RAGService-&gt;&gt;RAGService: Generate answer\n    RAGService--&gt;&gt;API: Answer + Context + Sources\n    API--&gt;&gt;Frontend: JSON Response\n    Frontend--&gt;&gt;User: Display answer &amp; context</code></pre>"},{"location":"reference/architecture/#api-architecture","title":"API Architecture","text":""},{"location":"reference/architecture/#requestresponse-models-pydantic","title":"Request/Response Models (Pydantic)","text":"<pre><code># Input Models\nTextInput\nNGramRequest\nRAGQueryRequest\nRAGSearchRequest\n\n# Response Models\nSentimentResponse\nWordFrequencyResponse\nTopicResponse\nStatsResponse\nRAGAnswerResponse\nRAGStatsResponse\n</code></pre>"},{"location":"reference/architecture/#middleware-stack","title":"Middleware Stack","text":"<pre><code>User Request\n    \u2193\nCORS Middleware (allow all origins in dev)\n    \u2193\nFastAPI Routing\n    \u2193\nPydantic Validation\n    \u2193\nEndpoint Handler\n    \u2193\nBusiness Logic (Services)\n    \u2193\nResponse Serialization\n    \u2193\nHTTP Response\n</code></pre>"},{"location":"reference/architecture/#error-handling-strategy","title":"Error Handling Strategy","text":"<pre><code>try:\n    # Business logic\nexcept SpecificError:\n    # Handle known errors\n    raise HTTPException(status_code=4xx)\nexcept Exception as e:\n    # Log unexpected errors\n    logger.error(f\"Error: {e}\")\n    raise HTTPException(status_code=500)\n</code></pre>"},{"location":"reference/architecture/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"reference/architecture/#docker-multi-stage-build","title":"Docker Multi-Stage Build","text":"<pre><code>graph TB\n    subgraph \"Stage 1: Builder\"\n        UV[uv Package Manager]\n        Deps[Install Dependencies]\n        UV --&gt; Deps\n    end\n\n    subgraph \"Stage 2: Runtime\"\n        Slim[Python 3.12-slim]\n        Copy[Copy Dependencies]\n        App[Copy Application Code]\n        Models[Download Models&lt;br/&gt;NLTK + Transformers]\n\n        Slim --&gt; Copy\n        Copy --&gt; App\n        App --&gt; Models\n    end\n\n    Deps -.-&gt;|Python packages| Copy</code></pre>"},{"location":"reference/architecture/#deployment-options","title":"Deployment Options","text":""},{"location":"reference/architecture/#option-1-render-via-docker-hub","title":"Option 1: Render (via Docker Hub)","text":"<pre><code>graph LR\n    GH[GitHub Actions] --&gt;|Build &amp; Push| DH[Docker Hub]\n    DH --&gt;|Auto-deploy| Render[Render Platform]\n    Render --&gt;|Serve| Users[End Users]</code></pre> <p>Flow: 1. Push to <code>main</code> branch 2. GitHub Actions builds Docker image 3. Push to Docker Hub (<code>trump-speeches-nlp-chatbot:latest</code>) 4. Render detects new image 5. Render pulls and deploys 6. Health check <code>/health</code></p>"},{"location":"reference/architecture/#option-2-azure-web-app","title":"Option 2: Azure Web App","text":"<p>Via ACR: <pre><code>graph LR\n    GH[GitHub Actions] --&gt;|Build &amp; Push| ACR[Azure Container&lt;br/&gt;Registry]\n    ACR --&gt;|Deploy| Azure[Azure Web App]\n    Azure --&gt;|Serve| Users[End Users]</code></pre></p> <p>Via Docker Hub: <pre><code>graph LR\n    GH[GitHub Actions] --&gt;|Build &amp; Push| DH[Docker Hub]\n    DH --&gt;|Deploy| Azure[Azure Web App]\n    Azure --&gt;|Serve| Users[End Users]</code></pre></p>"},{"location":"reference/architecture/#cicd-pipeline","title":"CI/CD Pipeline","text":"<pre><code>graph TB\n    Push[Push to main] --&gt; CI[CI Workflow]\n    Push --&gt; Security[Security Scan]\n\n    CI --&gt; Tests[Unit Tests&lt;br/&gt;Pytest]\n    CI --&gt; Lint[Code Quality&lt;br/&gt;flake8, black, mypy]\n\n    Security --&gt; PipAudit[pip-audit&lt;br/&gt;Dependency Check]\n    Security --&gt; Bandit[bandit&lt;br/&gt;Security Analysis]\n\n    Tests --&gt; Build[Build Docker Image]\n    Lint --&gt; Build\n    PipAudit --&gt; Build\n    Bandit --&gt; Build\n\n    Build --&gt; DHPush[Push to Docker Hub]\n    Build --&gt; ACRPush[Push to ACR]\n\n    DHPush --&gt; RenderDeploy[Deploy to Render]\n    ACRPush --&gt; AzureDeploy[Deploy to Azure]</code></pre>"},{"location":"reference/architecture/#technology-stack","title":"Technology Stack","text":""},{"location":"reference/architecture/#core-technologies","title":"Core Technologies","text":"Layer Technology Purpose API Framework FastAPI 0.116+ High-performance async API Web Server Uvicorn ASGI server LLM Integration Google Gemini 2.5 Flash Answer generation ML Framework PyTorch 2.5+ Deep learning backend NLP Library Transformers 4.57+ Pre-trained models Text Processing NLTK 3.9+ Tokenization, stopwords Vector DB ChromaDB 0.5+ Persistent embeddings storage Embeddings sentence-transformers 3.3+ Semantic embeddings (MPNet) Reranking Cross-encoder Precision optimization Keyword Search rank-bm25 Sparse retrieval RAG Framework LangChain 0.3+ Text splitting utilities"},{"location":"reference/architecture/#supporting-technologies","title":"Supporting Technologies","text":"Category Technology Version Dependency Mgmt uv Latest Containerization Docker Latest CI/CD GitHub Actions - Testing pytest 8.3+ Code Quality black, flake8, mypy, isort Latest Security pip-audit, bandit Latest"},{"location":"reference/architecture/#model-details","title":"Model Details","text":"Model Task Source Size Gemini 2.5 Flash Answer Generation Google AI API-based FinBERT Sentiment Analysis ProsusAI/finbert ~440MB all-mpnet-base-v2 Embeddings (768d) sentence-transformers ~420MB ms-marco-MiniLM Reranking cross-encoder ~80MB"},{"location":"reference/architecture/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"reference/architecture/#current-architecture","title":"Current Architecture","text":"<ul> <li>Compute: Single-instance deployment</li> <li>Storage: Local filesystem + ChromaDB</li> <li>Concurrency: Async FastAPI (handles concurrent requests)</li> </ul>"},{"location":"reference/architecture/#scaling-strategies","title":"Scaling Strategies","text":""},{"location":"reference/architecture/#1-horizontal-scaling","title":"1. Horizontal Scaling","text":"<pre><code>graph TB\n    LB[Load Balancer]\n    API1[API Instance 1]\n    API2[API Instance 2]\n    API3[API Instance 3]\n    SharedDB[(Shared ChromaDB&lt;br/&gt;Postgres pgvector)]\n\n    LB --&gt; API1\n    LB --&gt; API2\n    LB --&gt; API3\n\n    API1 --&gt; SharedDB\n    API2 --&gt; SharedDB\n    API3 --&gt; SharedDB</code></pre> <p>Required Changes: - Replace ChromaDB with pgvector (Postgres) or Pinecone - Use shared model storage (S3/Azure Blob) - Add Redis for caching</p>"},{"location":"reference/architecture/#2-vertical-scaling","title":"2. Vertical Scaling","text":"<p>Current Requirements: - RAM: ~2GB (models + API) - CPU: 1-2 cores - Storage: ~1GB (models + data)</p> <p>Optimized for: - RAM: 4-8GB for concurrent requests - CPU: 4+ cores for parallel processing - Storage: 5GB+ for larger datasets</p>"},{"location":"reference/architecture/#3-performance-optimizations","title":"3. Performance Optimizations","text":"<p>Already Implemented: - Multi-stage Docker builds - Model pre-loading on startup - Async request handling - Efficient text chunking</p> <p>Future Improvements: - Model quantization (reduce size) - GPU acceleration (CUDA support) - Response caching (Redis) - CDN for static files - Database connection pooling - Background task queues (Celery)</p>"},{"location":"reference/architecture/#resource-usage","title":"Resource Usage","text":"Component RAM CPU Storage FastAPI ~100MB Low - FinBERT ~1GB Medium 440MB all-MiniLM-L6-v2 ~200MB Low 80MB ChromaDB ~100MB Low Variable NLTK Data ~50MB Low 50MB Total ~2GB 1-2 cores ~1GB"},{"location":"reference/architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"reference/architecture/#current-security-measures","title":"Current Security Measures","text":"<ol> <li>Dependency Scanning: pip-audit (weekly)</li> <li>Code Analysis: bandit</li> <li>Input Validation: Pydantic models</li> <li>Non-root Container: User <code>appuser</code> (UID 1000)</li> <li>Health Checks: <code>/health</code> endpoint</li> </ol>"},{"location":"reference/architecture/#production-recommendations","title":"Production Recommendations","text":"<ol> <li>Authentication: Add API key validation</li> <li>Rate Limiting: Implement per-IP limits</li> <li>HTTPS: Use reverse proxy (Nginx)</li> <li>CORS: Restrict to specific origins</li> <li>Secrets Management: Use environment variables</li> <li>Logging: Centralized logging (ELK stack)</li> <li>Monitoring: Prometheus + Grafana</li> </ol>"},{"location":"reference/architecture/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"reference/architecture/#recommended-metrics","title":"Recommended Metrics","text":"<p>Application Metrics: - Request count (by endpoint) - Response time (p50, p95, p99) - Error rate (4xx, 5xx) - Model inference time</p> <p>System Metrics: - CPU usage - Memory usage - Disk I/O - Network I/O</p> <p>Business Metrics: - Total analyses performed - Most used endpoints - Average sentiment scores - RAG query accuracy</p>"},{"location":"reference/architecture/#implementation-example-prometheus","title":"Implementation Example (Prometheus)","text":"<pre><code>from prometheus_client import Counter, Histogram\n\nrequest_count = Counter('api_requests_total', 'Total requests', ['endpoint'])\nrequest_duration = Histogram('api_request_duration_seconds', 'Request duration')\n</code></pre>"},{"location":"reference/architecture/#future-architecture-enhancements","title":"Future Architecture Enhancements","text":""},{"location":"reference/architecture/#1-advanced-rag-features","title":"1. Advanced RAG Features","text":"<ul> <li>Query Caching: Redis layer for common questions</li> <li>Multi-modal: Support PDFs, images, audio transcripts</li> <li>Temporal Analysis: Sentiment trends over time</li> <li>Entity Relationships: Knowledge graph visualization</li> <li>Fine-tuned Embeddings: Domain-specific embedding models</li> </ul>"},{"location":"reference/architecture/#2-performance-optimizations","title":"2. Performance Optimizations","text":"<ul> <li>Async Processing: Background tasks for entity analytics</li> <li>GPU Acceleration: CUDA support for faster inference</li> <li>Model Quantization: Reduce model sizes</li> <li>Response Streaming: WebSocket support for real-time answers</li> </ul>"},{"location":"reference/architecture/#3-enhanced-nlp","title":"3. Enhanced NLP","text":"<ul> <li>Proper NER: spaCy or Hugging Face transformers for entity extraction</li> <li>Text Summarization: Automatic speech summarization</li> <li>Topic Modeling: LDA or BERTopic for theme discovery</li> <li>Fact Extraction: Structured information extraction</li> </ul>"},{"location":"reference/architecture/#4-deployment-scale","title":"4. Deployment &amp; Scale","text":"<ul> <li>Kubernetes: Container orchestration</li> <li>Auto-scaling: Based on request volume</li> <li>Multi-region: Global deployment</li> <li>CDN: Static asset delivery</li> </ul>"},{"location":"reference/architecture/#development-workflow","title":"Development Workflow","text":"<pre><code>graph LR\n    Dev[Local Development] --&gt;|Test| Test[pytest]\n    Test --&gt;|Lint| Lint[black, flake8, mypy]\n    Lint --&gt;|Commit| Git[Git Push]\n    Git --&gt;|Trigger| CI[GitHub Actions]\n    CI --&gt;|Build| Docker[Docker Build]\n    Docker --&gt;|Deploy| Env[Render/Azure]</code></pre>"},{"location":"reference/architecture/#references","title":"References","text":"<ul> <li>FastAPI Documentation</li> <li>Transformers Documentation</li> <li>ChromaDB Documentation</li> <li>LangChain Documentation</li> <li>Docker Best Practices</li> </ul> <p>Last Updated: October 2025 Version: 0.1.0 Maintainer: Kristiyan Bonev</p>"},{"location":"reference/rag-features/","title":"RAG System Features","text":""},{"location":"reference/rag-features/#overview","title":"Overview","text":"<p>This project implements a production-grade Retrieval-Augmented Generation (RAG) system for question-answering over a corpus of 35 political speeches (300,000+ words).</p>"},{"location":"reference/rag-features/#core-architecture","title":"Core Architecture","text":""},{"location":"reference/rag-features/#vector-database","title":"Vector Database","text":"<ul> <li>ChromaDB with persistent storage</li> <li>MPNet embeddings (768 dimensions) for semantic understanding</li> <li>Hybrid search combining dense embeddings with BM25 sparse retrieval</li> <li>Cross-encoder reranking for precision optimization</li> </ul>"},{"location":"reference/rag-features/#llm-integration","title":"LLM Integration","text":"<ul> <li>Google Gemini (gemini-2.5-flash) for answer generation</li> <li>Context-aware prompt engineering</li> <li>Entity-focused generation for targeted queries</li> <li>Fallback extraction for robustness</li> </ul>"},{"location":"reference/rag-features/#advanced-features","title":"Advanced Features","text":"<ul> <li>Multi-factor confidence scoring</li> <li>Entity extraction and analytics</li> <li>Sentiment analysis for entities</li> <li>Co-occurrence analysis</li> <li>Source attribution with citations</li> </ul>"},{"location":"reference/rag-features/#key-features","title":"Key Features","text":""},{"location":"reference/rag-features/#1-intelligent-question-answering","title":"1. Intelligent Question Answering","text":"<p>Ask natural language questions and receive AI-generated answers with supporting evidence.</p> <p>Example: <pre><code>response = rag.ask(\"What economic policies were discussed?\", top_k=5)\n</code></pre></p> <p>Response includes: - Generated answer from Gemini - 5 supporting context chunks - Confidence score with explanation - Source document attribution - Entity statistics (if applicable)</p>"},{"location":"reference/rag-features/#2-multi-factor-confidence-scoring","title":"2. Multi-Factor Confidence Scoring","text":"<p>Sophisticated confidence assessment considering: - Retrieval Quality (40%) \u2014 Semantic similarity of retrieved chunks - Consistency (25%) \u2014 Low variance in scores = higher confidence - Coverage (20%) \u2014 Number of supporting chunks - Entity Coverage (15%) \u2014 For entity queries, mention frequency</p> <p>Example output: <pre><code>{\n  \"confidence\": \"high\",\n  \"confidence_score\": 0.87,\n  \"confidence_explanation\": \"Overall confidence is HIGH (score: 0.87) based on excellent semantic match (similarity: 0.91), very consistent results (consistency: 0.93), 5 supporting context chunks\",\n  \"confidence_factors\": {\n    \"retrieval_score\": 0.91,\n    \"consistency\": 0.93,\n    \"chunk_coverage\": 5,\n    \"entity_coverage\": 0.84\n  }\n}\n</code></pre></p>"},{"location":"reference/rag-features/#3-entity-analytics","title":"3. Entity Analytics","text":"<p>Automatic entity detection with comprehensive statistics:</p> <ul> <li>Mention counts across entire corpus</li> <li>Speech coverage \u2014 which documents mention the entity</li> <li>Sentiment analysis \u2014 average sentiment toward entity</li> <li>Co-occurrence analysis \u2014 most common associated terms</li> </ul> <p>Example output: <pre><code>{\n  \"entity_statistics\": {\n    \"Biden\": {\n      \"mention_count\": 524,\n      \"speech_count\": 30,\n      \"corpus_percentage\": 25.03,\n      \"speeches\": [\"OhioSep21_2020.txt\", \"BemidjiSep18_2020.txt\", ...],\n      \"sentiment\": {\n        \"average_score\": -0.15,\n        \"classification\": \"Neutral\",\n        \"sample_size\": 50\n      },\n      \"associations\": [\"people\", \"our\", \"right\", \"about\", \"say\"]\n    }\n  }\n}\n</code></pre></p>"},{"location":"reference/rag-features/#4-hybrid-search","title":"4. Hybrid Search","text":"<p>Combines semantic and keyword search for optimal retrieval:</p> <ul> <li>Semantic search \u2014 Dense embeddings capture meaning and context</li> <li>BM25 keyword search \u2014 Ensures exact term matches aren't missed</li> <li>Cross-encoder reranking \u2014 Final precision optimization</li> <li>Configurable weights \u2014 Adjust semantic vs keyword importance</li> </ul>"},{"location":"reference/rag-features/#5-optimized-chunking","title":"5. Optimized Chunking","text":"<ul> <li>2048 character chunks (~512-768 tokens) for complete context</li> <li>150 character overlap to preserve continuity</li> <li>Smart splitting with RecursiveCharacterTextSplitter</li> <li>Maintains coherent context boundaries</li> </ul>"},{"location":"reference/rag-features/#api-usage","title":"API Usage","text":""},{"location":"reference/rag-features/#basic-question","title":"Basic Question","text":"<pre><code>import requests\n\nresponse = requests.post(\n    \"http://localhost:8000/rag/ask\",\n    json={\"question\": \"What was said about the economy?\", \"top_k\": 5}\n)\n\nresult = response.json()\nprint(result[\"answer\"])\nprint(f\"Confidence: {result['confidence']} ({result['confidence_score']:.2f})\")\n</code></pre>"},{"location":"reference/rag-features/#entity-query","title":"Entity Query","text":"<pre><code>response = requests.post(\n    \"http://localhost:8000/rag/ask\",\n    json={\"question\": \"What did Trump say about Biden?\", \"top_k\": 10}\n)\n\nresult = response.json()\n\n# View entity statistics\nif \"entity_statistics\" in result:\n    for entity, stats in result[\"entity_statistics\"].items():\n        print(f\"\\n{entity}:\")\n        print(f\"  Mentions: {stats['mention_count']}\")\n        print(f\"  Sentiment: {stats['sentiment']['classification']}\")\n        print(f\"  Associated: {', '.join(stats['associations'][:3])}\")\n</code></pre>"},{"location":"reference/rag-features/#semantic-search","title":"Semantic Search","text":"<pre><code>response = requests.post(\n    \"http://localhost:8000/rag/search\",\n    json={\"query\": \"immigration policy\", \"top_k\": 5}\n)\n\nresults = response.json()[\"results\"]\nfor i, result in enumerate(results, 1):\n    print(f\"\\n{i}. Source: {result['source']}\")\n    print(f\"   Similarity: {result['similarity']:.3f}\")\n    print(f\"   Preview: {result['text'][:100]}...\")\n</code></pre>"},{"location":"reference/rag-features/#configuration","title":"Configuration","text":""},{"location":"reference/rag-features/#ragservice-parameters","title":"RAGService Parameters","text":"<pre><code>from src.rag_service import RAGService\n\nrag = RAGService(\n    collection_name=\"speeches\",\n    persist_directory=\"./data/chromadb\",\n    embedding_model=\"all-mpnet-base-v2\",      # 768d embeddings\n    reranker_model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n    chunk_size=2048,                          # ~512-768 tokens\n    chunk_overlap=150,                        # ~100-150 tokens\n    use_llm=True,                             # Enable Gemini\n    use_reranking=True,                       # Enable cross-encoder\n    use_hybrid_search=True                    # Enable BM25 + semantic\n)\n</code></pre>"},{"location":"reference/rag-features/#api-endpoint-configuration","title":"API Endpoint Configuration","text":"<ul> <li>Default <code>top_k</code>: 5 chunks</li> <li>Maximum <code>top_k</code>: 15 chunks</li> <li>Increase for complex/entity queries</li> </ul>"},{"location":"reference/rag-features/#performance","title":"Performance","text":""},{"location":"reference/rag-features/#first-request","title":"First Request","text":"<ul> <li>~30-60 seconds (model downloads + document indexing)</li> <li>Downloads ~1-2 GB of models (one-time)</li> </ul>"},{"location":"reference/rag-features/#subsequent-requests","title":"Subsequent Requests","text":"<ul> <li>~1-3 seconds for typical queries</li> <li>~2-5 seconds for entity analytics (sentiment analysis)</li> </ul>"},{"location":"reference/rag-features/#optimization-opportunities","title":"Optimization Opportunities","text":"<ul> <li>Cache entity statistics</li> <li>Pre-compute embeddings</li> <li>Async sentiment analysis</li> <li>Redis for query caching</li> </ul>"},{"location":"reference/rag-features/#technical-details","title":"Technical Details","text":""},{"location":"reference/rag-features/#models-used","title":"Models Used","text":"<ul> <li>Embeddings: <code>sentence-transformers/all-mpnet-base-v2</code> (768d)</li> <li>Reranker: <code>cross-encoder/ms-marco-MiniLM-L-6-v2</code></li> <li>LLM: Google Gemini 2.5 Flash</li> <li>Sentiment: ProsusAI/finbert</li> </ul>"},{"location":"reference/rag-features/#database","title":"Database","text":"<ul> <li>ChromaDB 0.5.0 with SQLite persistence</li> <li>Vector index: HNSW for efficient similarity search</li> <li>Metadata filtering: Source, chunk index, timestamps</li> </ul>"},{"location":"reference/rag-features/#prompt-engineering","title":"Prompt Engineering","text":"<ul> <li>Context-limited to 4000 characters max</li> <li>Source attribution in context</li> <li>Entity-focused instructions when entities detected</li> <li>Structured output format</li> <li>Safety settings for political content</li> </ul>"},{"location":"reference/rag-features/#limitations-future-work","title":"Limitations &amp; Future Work","text":""},{"location":"reference/rag-features/#current-limitations","title":"Current Limitations","text":"<ul> <li>Entity extraction uses simple heuristics (capitalization)</li> <li>Sentiment analysis may show neutral for complex political text</li> <li>No query caching (every request recomputes)</li> <li>Synchronous processing (no async optimization)</li> </ul>"},{"location":"reference/rag-features/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Integrate proper NER (spaCy or Hugging Face)</li> <li>Add query caching layer (Redis)</li> <li>Implement async processing</li> <li>Add temporal analysis (sentiment over time)</li> <li>Entity relationship graphs</li> <li>Fine-tune embeddings on domain data</li> </ul>"},{"location":"reference/rag-features/#migration","title":"Migration","text":"<p>If you're upgrading from a previous version with different embeddings:</p> <pre><code>poetry run python scripts/migrate_rag_embeddings.py\n</code></pre> <p>This will: 1. Clear existing ChromaDB collection 2. Reload documents with new embeddings 3. Re-index all 35 speeches (~1082 chunks)</p>"},{"location":"reference/rag-features/#testing","title":"Testing","text":"<pre><code># Run RAG tests\npoetry run pytest tests/test_rag_service.py -v\n\n# Run all tests\npoetry run pytest -v\n</code></pre>"},{"location":"reference/rag-features/#documentation","title":"Documentation","text":"<ul> <li>API Reference: http://localhost:8000/docs</li> <li>Quick Start: <code>docs/QUICKSTART.md</code></li> <li>Deployment: <code>docs/DEPLOYMENT.md</code></li> <li>Testing: <code>docs/TESTING.md</code></li> </ul> <p>This RAG system demonstrates production-ready AI engineering with vector databases, LLM integration, and sophisticated retrieval techniques.</p>"}]}