###############################################################################
# Staging Configuration (YAML)
#
# Configuration for staging/pre-production environment.
# Use this to test production-like settings before deploying to prod.
###############################################################################

# ---------------------------------------------------------------------------
# Core application metadata
# ---------------------------------------------------------------------------
environment: staging
log_level: INFO
app_name: "Trump Speeches NLP Chatbot API (Staging)"
app_version: "0.1.0"

# ---------------------------------------------------------------------------
# API settings
# ---------------------------------------------------------------------------
api:
  host: "0.0.0.0"
  port: 8000
  reload: false                    # No hot reload in staging
  cors_origins:
    - "https://staging.yourdomain.com"  # Replace with your staging domain

# ---------------------------------------------------------------------------
# RAG (Retrieval-Augmented Generation) configuration
# ---------------------------------------------------------------------------
rag:
  chromadb_persist_directory: "./data/chromadb"
  chromadb_collection_name: "speeches"

  chunk_size: 2048
  chunk_overlap: 150

  default_top_k: 5
  use_reranking: true
  use_hybrid_search: true

# ---------------------------------------------------------------------------
# ML model configuration
# ---------------------------------------------------------------------------
models:
  sentiment_model_name: "ProsusAI/finbert"
  embedding_model_name: "all-mpnet-base-v2"
  reranker_model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  emotion_model_name: "j-hartmann/emotion-english-distilroberta-base"

# ---------------------------------------------------------------------------
# Data paths
# ---------------------------------------------------------------------------
paths:
  data_root_directory: "./data"
  speeches_directory: "./data/Donald Trump Rally Speeches"

# ---------------------------------------------------------------------------
# LLM configuration (non-sensitive defaults)
# ---------------------------------------------------------------------------
llm:
  provider: "gemini"
  enabled: true
  model_name: "gemini-2.5-flash"
  temperature: 0.3
  max_output_tokens: 1024

  # NOTE: LLM_API_KEY should be set via environment variables or .env file
